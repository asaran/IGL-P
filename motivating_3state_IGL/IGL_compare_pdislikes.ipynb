{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy helper function"
      ],
      "metadata": {},
      "id": "matched-recipient"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class EasyAcc:\n",
        "    def __init__(self):\n",
        "        self.n = 0\n",
        "        self.sum = 0\n",
        "        self.sumsq = 0\n",
        "\n",
        "    def __iadd__(self, other):\n",
        "        self.n += 1\n",
        "        self.sum += other\n",
        "        self.sumsq += other*other\n",
        "        return self\n",
        "\n",
        "    def __isub__(self, other):\n",
        "        self.n += 1\n",
        "        self.sum -= other\n",
        "        self.sumsq += other*other\n",
        "        return self\n",
        "\n",
        "    def mean(self):\n",
        "        return self.sum / max(self.n, 1)\n",
        "\n",
        "    def var(self):\n",
        "        from math import sqrt\n",
        "        return sqrt(self.sumsq / max(self.n, 1) - self.mean()**2)\n",
        "\n",
        "    def semean(self):\n",
        "        from math import sqrt\n",
        "        return self.var() / sqrt(max(self.n, 1))"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "code_folding": [
          2,
          31,
          53,
          72,
          83,
          112,
          150,
          151
        ],
        "gather": {
          "logged": 1670342604234
        }
      },
      "id": "norman-arcade"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inverse kinematics"
      ],
      "metadata": {},
      "id": "operating-longer"
    },
    {
      "cell_type": "code",
      "source": [
        "class IK(torch.nn.Module):\n",
        "    def __init__(self, dim_x, dim_a, dim_y):\n",
        "        super().__init__()\n",
        "        self.bilinear = torch.nn.Bilinear(in1_features=dim_x*dim_a, in2_features=dim_y, out_features=1)\n",
        "        self.softmax = torch.nn.Softmax(dim=-1)\n",
        "        \n",
        "    # Xs --> [batch, dim_x] \n",
        "    # As --> [batch, num_a, dim_a] \n",
        "    # Ys --> [batch, dim_y]\n",
        "    def prelogits(self, Xs, As, Ys):\n",
        "        batch, numa, dima = As.shape\n",
        "        _, dimx = Xs.shape\n",
        "        \n",
        "        xview = Xs.unsqueeze(1).unsqueeze(3)            # [ batch, 1, dim_x, 1 ]\n",
        "        aview = As.unsqueeze(2)                         # [ batch, num_a, 1, dim_a ]\n",
        "        xaouter = torch.matmul(xview, aview)            # [ batch, num_a, dim_x, dim_a ]\n",
        "        yview = Ys.unsqueeze(1).expand(-1, numa, -1)    # [ batch, num_a, dim_y ]\n",
        "        return self.bilinear(xaouter.reshape(-1, numa, dimx*dima), yview.contiguous()).reshape(-1, numa)\n",
        "    \n",
        "    def predictions(self, prelogits):\n",
        "        return self.softmax(prelogits)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1670342604467
        }
      },
      "id": "oriental-chaos"
    },
    {
      "cell_type": "code",
      "source": [
        "class BilinearPredictor(torch.nn.Module):\n",
        "    def __init__(self, dim_x, dim_a):\n",
        "        super().__init__()\n",
        "        if dim_x * dim_a > 0:\n",
        "            self.bilinear = torch.nn.Bilinear(in1_features=dim_x, in2_features=dim_a, out_features=1)\n",
        "        else:\n",
        "            self.bilinear = None\n",
        "            self.b = torch.nn.Parameter(torch.zeros(1))\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        \n",
        "    def prelogits(self, Xs, As):\n",
        "        if self.bilinear is not None:\n",
        "            return self.bilinear(Xs.contiguous(), As.contiguous()).squeeze(1)\n",
        "        else:\n",
        "            return self.b.expand(Xs.shape[0])\n",
        "    \n",
        "    def prediction(self, prelogits):\n",
        "        return self.sigmoid(prelogits)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1670342604629
        }
      },
      "id": "solved-canada"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploration policy"
      ],
      "metadata": {},
      "id": "silver-cooper"
    },
    {
      "cell_type": "code",
      "source": [
        "class Policy(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        pass\n",
        "    \n",
        "    def sample(self, Fs):\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def update(self, dt):\n",
        "        raise NotImplementedError\n",
        "        \n",
        "class EpsilonGreedy(Policy):\n",
        "    def __init__(self, epsilon, epsilon_t0):\n",
        "        super().__init__()\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_t0 = epsilon_t0\n",
        "        self.t = epsilon_t0\n",
        "        \n",
        "    def myeps(self):\n",
        "        return self.epsilon * (self.epsilon_t0 / self.t)**(1/3)\n",
        "        \n",
        "    def sample(self, Fs, As):\n",
        "        myeps = self.myeps()\n",
        "        \n",
        "        unif = torch.rand(size=(Fs.shape[0], 1))\n",
        "        should_explore = (unif < myeps).long()\n",
        "        \n",
        "        explore = torch.randint(low=0, high=Fs.shape[1], size=(Fs.shape[0], 1))\n",
        "        exploit = torch.max(Fs, dim=1, keepdim=True).indices\n",
        "        aindex = exploit + should_explore * (explore - exploit)\n",
        "        \n",
        "        action = torch.gather(input=As, dim=1, index=aindex.unsqueeze(2).expand(-1, -1, As.shape[2])).squeeze(1)\n",
        "        isgreedy = (aindex == exploit).long()\n",
        "        paction = myeps * torch.ones(size=(Fs.shape[0],1))/Fs.shape[1] + isgreedy * (1 - myeps)\n",
        "        \n",
        "        return action, paction, aindex\n",
        "    \n",
        "    def update(self, dt):\n",
        "        self.t += dt"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1670342604785
        }
      },
      "id": "invalid-plumbing"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up simulator"
      ],
      "metadata": {},
      "id": "determined-chosen"
    },
    {
      "cell_type": "code",
      "source": [
        "class Simulator(torch.utils.data.Dataset):\n",
        "    def __init__(self, *, T, nusers, nactions, pdislike, seed):\n",
        "        import random\n",
        "\n",
        "        assert nusers > 1\n",
        "        assert nactions > 2\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.random = random.Random(seed)\n",
        "        self.nusers = nusers\n",
        "        self.nactions = nactions\n",
        "        self.actions = torch.eye(self.nactions)\n",
        "        self.feedbacks = [ 'click', 'like', 'dislike', 'skip', 'none']\n",
        "        self.pdislike = pdislike\n",
        "\n",
        "        # User's ground truth preference\n",
        "        # This is only used to evaluate IGL learning result\n",
        "        # Never revealed to IGL algorithm\n",
        "        self.enjoys = {}\n",
        "        self.hates = {}\n",
        "        \n",
        "        for n in range(nusers):            \n",
        "            enjoy_action, hate_action = self.random.sample(list(range(nactions)), 2)\n",
        "            self.enjoys[n] = enjoy_action\n",
        "            self.hates[n] = hate_action\n",
        "        \n",
        "        self.contexts = torch.Tensor([ self.random.randint(0, self.nusers-1) for _ in range(T) ]).long()\n",
        "        self.random = random.Random(1664525*seed + 1013904223)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.contexts)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        context = torch.nn.functional.one_hot(self.contexts[idx], num_classes=self.nusers).float()\n",
        "        return context, self.actions\n",
        "\n",
        "    def first_nonzero(self, x, axis=0):\n",
        "        nonz = (x != 0)\n",
        "        return ((nonz.cumsum(axis) == 1) & nonz).max(axis, keepdim=True)\n",
        "    \n",
        "    def get_one_hot_id(self, onehot):\n",
        "        return self.first_nonzero(onehot, axis=-1)[1].squeeze().item()\n",
        "        \n",
        "    def enjoys_the_action(self, Xs, As):\n",
        "        user_id = self.get_one_hot_id(Xs)\n",
        "        action_id = self.get_one_hot_id(As)\n",
        "        return self.enjoys[user_id] == action_id\n",
        "    \n",
        "    def hates_the_action(self, Xs, As):\n",
        "        user_id = self.get_one_hot_id(Xs)\n",
        "        action_id = self.get_one_hot_id(As)\n",
        "        return self.hates[user_id] == action_id"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1670342604945
        }
      },
      "id": "verbal-break"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 states simulator"
      ],
      "metadata": {},
      "id": "c7bd5952"
    },
    {
      "cell_type": "code",
      "source": [
        "class ThreeStatesSimulator(Simulator):\n",
        "    def sample_feedback(self, Xs, As):\n",
        "        results = []\n",
        "        for context, chosen_action in zip(Xs, As):\n",
        "            if self.enjoys_the_action(context, chosen_action):\n",
        "                probs = [ 0.75, 0.25, 0, 0, 0 ]\n",
        "            elif self.hates_the_action(context, chosen_action):\n",
        "                probs = [ 0, 0, self.pdislike, 1 - self.pdislike, 0 ]\n",
        "            else:\n",
        "                probs = [ 0, 0, 0, 0, 1 ]\n",
        "        \n",
        "            feedback = self.random.choices(list(range(len(self.feedbacks))), weights=probs)[0]\n",
        "            results.append(torch.nn.functional.one_hot(torch.LongTensor([feedback]), num_classes = len(self.feedbacks)).float())\n",
        "        return torch.cat(results, dim=0)\n",
        "    \n",
        "    def is_definitely_negative(self, Xs, Ys):\n",
        "        return self.first_nonzero(Ys, axis=-1)[1].squeeze(1) == 2\n",
        "    \n",
        "    def true_reward(self, Xs, As):\n",
        "        return [ self.enjoys_the_action(x, a) - self.hates_the_action(x, a) for x, a in zip(Xs, As) ]"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1670342605096
        }
      },
      "id": "01917a9c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Epsilon-Greedy"
      ],
      "metadata": {},
      "id": "charged-sewing"
    },
    {
      "cell_type": "code",
      "source": [
        "def run_sim(*, seed, T=150_000, batch_size=100, pdislike=0.1, n_states=2):\n",
        "    from math import sqrt\n",
        "    import itertools\n",
        "    \n",
        "    def binent(p):\n",
        "        from math import log\n",
        "        return -p * log(p) - (1 - p) * log(1 - p) \n",
        "\n",
        "    nusers = 5\n",
        "    nactions = 11\n",
        "    lr = 0.001\n",
        "    epsilon = 1\n",
        "    epsilon_t0 = 100\n",
        "    \n",
        "    # n_states - 1 -> the number of latent states we are certain with\n",
        "    n_extreme_states = n_states - 1\n",
        "    optimal_accuracy = ((nactions - n_extreme_states) / nactions) * (1 / (nactions - n_extreme_states)) + ((1/nactions) * 1) * n_extreme_states\n",
        "    print(f'optimal action prediction accuracy = {optimal_accuracy : .4f}')\n",
        "    print(f'optimal neg log loss = {(1/2 * binent(pdislike)):.4f}')\n",
        "    print(f'optimal const log loss = {binent(pdislike / 2):.4f}')\n",
        "\n",
        "    true_rewards = []\n",
        "\n",
        "    sim = ThreeStatesSimulator(T=T, nusers=nusers, nactions=nactions, pdislike=pdislike, seed=seed); seed += 1\n",
        "        \n",
        "    torch.manual_seed(seed); seed += 1\n",
        "    loader = torch.utils.data.DataLoader(sim, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    policy = EpsilonGreedy(epsilon, epsilon_t0)\n",
        "\n",
        "    ik = IK(dim_x=nusers, dim_a=nactions, dim_y=len(sim.feedbacks))\n",
        "    negpredictor = BilinearPredictor(dim_x=nusers, dim_a=nactions)\n",
        "    constpredictor = BilinearPredictor(dim_x=0, dim_a=0)\n",
        "    rewardpredictor = BilinearPredictor(dim_x=nusers, dim_a=nactions)\n",
        "\n",
        "    actionloss = torch.nn.CrossEntropyLoss(reduction='none')\n",
        "    actionoptimizer = torch.optim.Adam(ik.parameters(), lr=lr*sqrt(batch_size))\n",
        "    negloss = torch.nn.BCEWithLogitsLoss(reduction='none')\n",
        "    negoptimizer = torch.optim.Adam(itertools.chain(negpredictor.parameters(), constpredictor.parameters()), lr=lr*sqrt(batch_size))\n",
        "    regloss = torch.nn.MSELoss(reduction='none')\n",
        "    regoptimizer = torch.optim.Adam(rewardpredictor.parameters(), lr=lr*sqrt(batch_size))\n",
        "\n",
        "    print('{:<5s}\\t{:<8s} {:<8s}\\t{:<8s} {:<8s}\\t{:<8s} {:<8s}\\t{:<8s} {:<8s}\\t{:<8s} {:<8s}\\t{:<8s} {:<8s}\\t{:<8s} {:<8s}\\t{:<8s}'.format(\n",
        "        'bno',  'loss', 'since', 'acc', 'since', 'neg', 'since', 'const', 'since', 'reg', 'since', 'pol', 'since', 'greedy', 'since', 'eps'), flush=True) \n",
        "    avloss, avacc, avnegloss, avconstloss, avregloss, avpol, avgreedy = [ EasyAcc() for _ in range(7) ]\n",
        "    avlosssincelast, avaccsincelast, avneglosssincelast, avconstlosssincelast, avreglosssincelast, avpolsincelast, avgreedysincelast = [ EasyAcc() for _ in range(7) ]\n",
        "    \n",
        "    for bno, minibatch in enumerate(loader):\n",
        "        Xs, As = minibatch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            rhat = rewardpredictor.prelogits(Xs.unsqueeze(1).expand(-1, As.shape[1], -1), As).squeeze(2)\n",
        "            action, paction, aindex = policy.sample(rhat, As)\n",
        "            \n",
        "            truerewards = torch.Tensor(sim.true_reward(Xs, action))\n",
        "            avpol += torch.mean(truerewards).item()\n",
        "            avpolsincelast += torch.mean(truerewards).item()\n",
        "            \n",
        "            true_rewards.append(torch.mean(truerewards).item())\n",
        "\n",
        "            greedy = torch.max(rhat, dim=1, keepdim=True).indices\n",
        "            greedyaction = torch.gather(input=As, dim=1, index=greedy.unsqueeze(2).expand(-1, -1, As.shape[2])).squeeze(1)\n",
        "            greedyrewards = torch.Tensor(sim.true_reward(Xs, greedyaction))\n",
        "            avgreedy += torch.mean(greedyrewards).item()\n",
        "            avgreedysincelast += torch.mean(greedyrewards).item()\n",
        "\n",
        "            Ys = sim.sample_feedback(Xs, action)\n",
        "            \n",
        "        actionoptimizer.zero_grad()\n",
        "        prepapred = ik.prelogits(Xs, As, Ys)\n",
        "        \n",
        "        rawactionloss = actionloss(prepapred, aindex.squeeze(1)).unsqueeze(1)\n",
        "        actioniw = 1/(As.shape[1]*paction)\n",
        "        batchactionloss = torch.sum(torch.mul(actioniw, rawactionloss)) / torch.sum(actioniw)\n",
        "        batchactionloss.backward() #learn\n",
        "        actionoptimizer.step()\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            papred = torch.gather(input=ik.predictions(prepapred), index=aindex, dim=1).squeeze()\n",
        "            isExtreme = papred > (2 / As.shape[1])\n",
        "            \n",
        "        if torch.any(isExtreme):\n",
        "            extremeXs = torch.atleast_2d(Xs[isExtreme])\n",
        "            extremeAs = torch.atleast_2d(action[isExtreme])\n",
        "            extremeYs = torch.atleast_2d(Ys[isExtreme])\n",
        "            extremepaction = torch.atleast_2d(paction[isExtreme])\n",
        "            with torch.no_grad():\n",
        "                isNeg = sim.is_definitely_negative(extremeXs, extremeYs).float()\n",
        "                \n",
        "            negoptimizer.zero_grad()\n",
        "            negpred = negpredictor.prelogits(extremeXs, extremeAs)\n",
        "            constpred = constpredictor.prelogits(torch.empty(extremeXs.shape[0], 0), None)\n",
        "            extremeactioniw = 1/(As.shape[1]*extremepaction)\n",
        "            batchnegloss = torch.sum(torch.mul(extremeactioniw, negloss(negpred, isNeg).unsqueeze(1))) / torch.sum(extremeactioniw)\n",
        "            batchconstloss = torch.sum(torch.mul(extremeactioniw, negloss(constpred, isNeg).unsqueeze(1))) / torch.sum(extremeactioniw)\n",
        "            (batchnegloss + batchconstloss).backward()\n",
        "            negoptimizer.step()\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                fakereward = torch.zeros(Xs.shape[0])\n",
        "                fakereward[isExtreme] = 1 - 2 * (negpred > constpred).float()\n",
        "\n",
        "                states, counts = fakereward.unique(return_counts=True)\n",
        "                \n",
        "            regoptimizer.zero_grad()\n",
        "            rewardpred = rewardpredictor.prelogits(Xs, action)\n",
        "            batchregloss = torch.sum(torch.mul(actioniw, regloss(rewardpred, fakereward).unsqueeze(1))) / torch.sum(actioniw)\n",
        "            batchregloss.backward()\n",
        "            regoptimizer.step()\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                policy.update(Xs.shape[0])\n",
        "        else:\n",
        "            batchnegloss = None\n",
        "\n",
        "        with torch.no_grad():\n",
        "            avloss += batchactionloss.item()\n",
        "            avlosssincelast += batchactionloss.item()\n",
        "            if batchnegloss is not None:\n",
        "                avnegloss += batchnegloss.item()\n",
        "                avneglosssincelast += batchnegloss.item()\n",
        "                avconstloss += batchconstloss.item()\n",
        "                avconstlosssincelast += batchconstloss.item()\n",
        "                avregloss += batchregloss.item()\n",
        "                avreglosssincelast += batchregloss.item()\n",
        "                \n",
        "            amaxpred = torch.max(prepapred, dim=1, keepdim=True)\n",
        "            avacc += torch.mean(torch.mul(actioniw, (aindex == amaxpred.indices).float())).item()\n",
        "            avaccsincelast += torch.mean(torch.mul(actioniw, (aindex == amaxpred.indices).float())).item()\n",
        "\n",
        "            if bno & (bno - 1) == 0:\n",
        "                print('{:<5d}\\t{:<8.5f} {:<8.5f}\\t{:<8.5f} {:<8.5f}\\t{:<8.5f} {:<8.5f}\\t{:<8.5f} {:<8.5f}\\t{:<8.5f} {:<8.5f}\\t{:<8.5f} {:<8.5f}\\t{:<8.5f} {:<8.5f}\\t{:<8.5f}'.format( \n",
        "                    bno,  \n",
        "                    avloss.mean(), avlosssincelast.mean(),\n",
        "                    avacc.mean(), avaccsincelast.mean(),\n",
        "                    avnegloss.mean(), avneglosssincelast.mean(),\n",
        "                    avconstloss.mean(), avconstlosssincelast.mean(),\n",
        "                    avregloss.mean(), avreglosssincelast.mean(),\n",
        "                    avpol.mean(), avpolsincelast.mean(),\n",
        "                    avgreedy.mean(), avgreedysincelast.mean(),\n",
        "                    policy.myeps(),\n",
        "                ), flush=True)\n",
        "                avlosssincelast, avaccsincelast, avneglosssincelast, avconstlosssincelast, avreglosssincelast, avpolsincelast, avgreedysincelast = [ EasyAcc() for _ in range(7) ]\n",
        "\n",
        "    print('{:<5d}\\t{:<8.5f} {:<8.5f}\\t{:<8.5f} {:<8.5f}\\t{:<8.5f} {:<8.5f}\\t{:<8.5f} {:<8.5f}\\t{:<8.5f} {:<8.5f}\\t{:<8.5f} {:<8.5f}\\t{:<8.5f} {:<8.5f}\\t{:<8.5f}'.format( \n",
        "        bno,  \n",
        "        avloss.mean(), avlosssincelast.mean(),\n",
        "        avacc.mean(), avaccsincelast.mean(),\n",
        "        avnegloss.mean(), avneglosssincelast.mean(),\n",
        "        avconstloss.mean(), avconstlosssincelast.mean(),\n",
        "        avregloss.mean(), avreglosssincelast.mean(),\n",
        "        avpol.mean(), avpolsincelast.mean(),\n",
        "        avgreedy.mean(), avgreedysincelast.mean(),\n",
        "        policy.myeps()\n",
        "    ), flush=True)\n",
        "    return true_rewards\n"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "code_folding": [
          0,
          4,
          139
        ],
        "gather": {
          "logged": 1670342605255
        }
      },
      "id": "different-fellowship"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot helper function"
      ],
      "metadata": {},
      "id": "regular-singer"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_result(true_rewards):\n",
        "    from matplotlib import pyplot as plt\n",
        "    from matplotlib import rc\n",
        "    import pandas as pd\n",
        "\n",
        "    rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
        "    rc('text', usetex=True)\n",
        "    \n",
        "    legend_font_size = 14\n",
        "    tick_font_size = 14\n",
        "    label_font_size = 16\n",
        "    xlim = 1450\n",
        "    ylim = 1\n",
        "\n",
        "    color_1 = (51/255,34/255,136/255)\n",
        "    color_2 = (17/255,119/255,51/255)\n",
        "    color_4 = (221/255,204/255,119/255)\n",
        "    color_8 = (170/255,68/255,153/255)\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(6, 2.5))\n",
        "    plt.plot(pd.Series(true_rewards[3]).rolling(5).mean(),color=color_8,label='$p=0.8$')\n",
        "    plt.plot(pd.Series(true_rewards[2]).rolling(5).mean(),color=color_4,label='$p=0.4$')\n",
        "    plt.plot(pd.Series(true_rewards[1]).rolling(5).mean(),color=color_2,label='$p=0.2$')\n",
        "    plt.plot(pd.Series(true_rewards[0]).rolling(5).mean(),color=color_1,label='$p=0.1$')\n",
        "\n",
        "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=legend_font_size)\n",
        "    plt.xticks(fontsize=tick_font_size)\n",
        "    plt.yticks(fontsize=tick_font_size)\n",
        "    plt.xlabel('number of iterations', fontsize=label_font_size)\n",
        "    plt.ylabel('average reward', fontsize=label_font_size)\n",
        "    plt.xlim(0, xlim)\n",
        "    plt.ylim(-0.1, ylim)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1670342605410
        }
      },
      "id": "employed-congress"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run simulation"
      ],
      "metadata": {},
      "id": "suitable-partition"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare different pdislikes"
      ],
      "metadata": {},
      "id": "signal-strike"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import math\n",
        "\n",
        "def compare_pdislikes(*, seeds, pdislikes, T=150_000, batch_size=100):\n",
        "    true_all = []\n",
        "    t = math.floor(T/batch_size)\n",
        "\n",
        "    for pdislike in pdislikes:\n",
        "        true_r_tmp = []\n",
        "        for seed in seeds:\n",
        "            true_r = run_sim(seed=seed, T=T, batch_size=batch_size, pdislike=pdislike, n_states=3)\n",
        "            true_r_tmp.append(true_r)\n",
        "        true_all.append([])\n",
        "\n",
        "        for j in range(t):\n",
        "            tmp = []\n",
        "            for i in range(len(true_r_tmp)):\n",
        "                tmp.append(true_r_tmp[i][j])\n",
        "            true_all[-1].append(np.mean(tmp))\n",
        "    plot_result(true_all)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1670342605579
        }
      },
      "id": "9fe63760"
    },
    {
      "cell_type": "code",
      "source": [
        "compare_pdislikes(\n",
        "    seeds=[1, 13, 19, 23, 29, 31, 37, 39, 41, 43],\n",
        "    pdislikes = [0.1, 0.2, 0.4, 0.8]\n",
        ")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "optimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.1625\noptimal const log loss = 0.1985\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39571  2.39571 \t0.04000  0.04000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.03000  0.03000 \t0.24000  0.24000 \t1.00000 \n1    \t2.39561  2.39552 \t0.04500  0.05000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.03000  0.03000 \t0.21500  0.19000 \t1.00000 \n2    \t2.39310  2.38809 \t0.06667  0.11000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02333  0.01000 \t0.19333  0.15000 \t1.00000 \n4    \t2.39356  2.39423 \t0.09400  0.13500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02000  0.01500 \t0.18000  0.16000 \t1.00000 \n8    \t2.38582  2.37614 \t0.13556  0.18750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01333  0.00500 \t0.18889  0.20000 \t1.00000 \n16   \t2.36761  2.34713 \t0.19000  0.25125 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00706 -0.03000\t0.19294  0.19750 \t1.00000 \n32   \t2.33309  2.29642 \t0.23455  0.28187 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00515  0.01813 \t0.19061  0.18812 \t1.00000 \n64   \t2.27822  2.22163 \t0.25115  0.26828 \t0.72421  0.72421 \t0.64965  0.64965 \t0.20778  0.20778 \t0.01846  0.03219 \t0.16692  0.14250 \t0.36840 \n128  \t2.19252  2.10549 \t0.26231  0.27365 \t0.49030  0.42086 \t0.52486  0.48781 \t0.15427  0.13838 \t0.10512  0.19312 \t0.21752  0.26891 \t0.22834 \n256  \t2.08918  1.98504 \t0.26375  0.26520 \t0.34567  0.25188 \t0.40501  0.32729 \t0.08899  0.04667 \t0.27206  0.44031 \t0.37922  0.54219 \t0.16771 \n512  \t1.97018  1.85071 \t0.26716  0.27058 \t0.25855  0.18674 \t0.30634  0.22502 \t0.05714  0.03089 \t0.27645  0.28086 \t0.35548  0.33164 \t0.12880 \n1024 \t1.89332  1.81630 \t0.26582  0.26447 \t0.20705  0.16008 \t0.24790  0.19459 \t0.03931  0.02305 \t0.54486  0.81379 \t0.63487  0.91480 \t0.10068 \n1499 \t1.86217  1.79497 \t0.26731  0.27054 \t0.17448  0.10736 \t0.20975  0.13112 \t0.02648  0.00002 \t0.65863  0.90415 \t0.75049  1.00000 \t0.08825 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.1625\noptimal const log loss = 0.1985\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.40226  2.40226 \t0.08000  0.08000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01000  0.01000 \t-0.11000 -0.11000\t1.00000 \n1    \t2.39809  2.39392 \t0.09500  0.11000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01000  0.01000 \t-0.15000 -0.19000\t1.00000 \n2    \t2.39769  2.39689 \t0.08667  0.07000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02333  0.05000 \t-0.17333 -0.22000\t1.00000 \n4    \t2.39258  2.38492 \t0.09800  0.11500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00200 -0.04000\t-0.20400 -0.25000\t1.00000 \n8    \t2.38154  2.36773 \t0.12889  0.16750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00444 -0.00750\t-0.21000 -0.21750\t1.00000 \n16   \t2.36280  2.34172 \t0.20294  0.28625 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00588 -0.00750\t-0.20353 -0.19625\t1.00000 \n32   \t2.33452  2.30446 \t0.23424  0.26750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00212 0.00187 \t-0.20030 -0.19688\t1.00000 \n64   \t2.28235  2.22855 \t0.25221  0.27073 \t0.44315  0.44315 \t0.64501  0.64501 \t0.11520  0.11520 \t0.00969  0.02187 \t-0.12569 -0.04875\t0.35688 \n128  \t2.19223  2.10071 \t0.26902  0.28611 \t0.33595  0.30078 \t0.52241  0.48218 \t0.08250  0.07177 \t0.05357  0.09813 \t-0.00124 0.12516 \t0.22655 \n256  \t2.08528  1.97749 \t0.27074  0.27247 \t0.26384  0.21595 \t0.40053  0.31960 \t0.03838  0.00909 \t0.11409  0.17508 \t0.10444  0.21094 \t0.16718 \n512  \t1.97069  1.85565 \t0.27294  0.27514 \t0.20453  0.15519 \t0.29083  0.19955 \t0.02051  0.00563 \t0.21119  0.30867 \t0.23158  0.35922 \t0.12862 \n1024 \t1.89062  1.81039 \t0.27731  0.28170 \t0.17970  0.15695 \t0.23617  0.18610 \t0.02607  0.03116 \t0.52493  0.83928 \t0.58939  0.94789 \t0.10061 \n1499 \t1.85975  1.79314 \t0.27451  0.26845 \t0.15287  0.09745 \t0.19867  0.12123 \t0.01764  0.00024 \t0.64605  0.90743 \t0.71941  1.00000 \t0.08821 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.1625\noptimal const log loss = 0.1985\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39286  2.39286 \t0.13000  0.13000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02000  0.02000 \t0.00000  0.00000 \t1.00000 \n1    \t2.40455  2.41624 \t0.09500  0.06000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.04500  0.07000 \t0.00000  0.00000 \t1.00000 \n2    \t2.40214  2.39731 \t0.11000  0.14000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01667  -0.04000\t0.00000  0.00000 \t1.00000 \n4    \t2.39673  2.38860 \t0.12400  0.14500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00400 -0.03500\t0.00000  0.00000 \t1.00000 \n8    \t2.38937  2.38018 \t0.14111  0.16250 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01556  0.04000 \t0.00000  0.00000 \t1.00000 \n16   \t2.37706  2.36322 \t0.17765  0.21875 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00118  -0.01500\t0.00000  0.00000 \t1.00000 \n32   \t2.34629  2.31360 \t0.22576  0.27687 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00667  0.01250 \t0.00000  0.00000 \t1.00000 \n64   \t2.28824  2.22837 \t0.24900  0.27296 \t0.63664  0.63664 \t0.64041  0.64041 \t0.18219  0.18219 \t-0.02877 -0.06531\t-0.05215 -0.10594\t0.34668 \n128  \t2.20115  2.11270 \t0.25967  0.27051 \t0.47530  0.41733 \t0.52712  0.48641 \t0.14544  0.13222 \t-0.13961 -0.25219\t-0.19380 -0.33766\t0.22482 \n256  \t2.08747  1.97291 \t0.27036  0.28114 \t0.34440  0.25543 \t0.40643  0.32440 \t0.08811  0.04915 \t-0.13156 -0.12344\t-0.17230 -0.15062\t0.16667 \n512  \t1.97804  1.86818 \t0.27096  0.27156 \t0.28768  0.24005 \t0.33496  0.27494 \t0.05571  0.02849 \t-0.04865 0.03457 \t-0.06335 0.04602 \t0.12844 \n1024 \t1.90104  1.82389 \t0.27028  0.26959 \t0.20920  0.13700 \t0.24658  0.16527 \t0.03995  0.02545 \t0.37138  0.79223 \t0.41352  0.89133 \t0.10054 \n1499 \t1.87051  1.80464 \t0.27471  0.28427 \t0.17554  0.10590 \t0.20885  0.13077 \t0.02695  0.00004 \t0.53997  0.90379 \t0.59924  1.00000 \t0.08817 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.1625\noptimal const log loss = 0.1985\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.40005  2.40005 \t0.08000  0.08000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.02000 -0.02000\t-0.18000 -0.18000\t1.00000 \n1    \t2.39923  2.39841 \t0.08000  0.08000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01500  0.05000 \t-0.18500 -0.19000\t1.00000 \n2    \t2.39718  2.39310 \t0.11667  0.19000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00333  -0.02000\t-0.19667 -0.22000\t1.00000 \n4    \t2.39638  2.39517 \t0.11200  0.10500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02800  0.06500 \t-0.18400 -0.16500\t1.00000 \n8    \t2.38644  2.37403 \t0.14444  0.18500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01111  -0.01000\t-0.18333 -0.18250\t1.00000 \n16   \t2.36925  2.34991 \t0.17529  0.21000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01176  0.01250 \t-0.19353 -0.20500\t1.00000 \n32   \t2.33983  2.30858 \t0.21121  0.24937 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00333  -0.00562\t-0.19333 -0.19313\t1.00000 \n64   \t2.28803  2.23460 \t0.23186  0.25315 \t0.81895  0.81895 \t0.64732  0.64732 \t0.13288  0.13288 \t-0.01369 -0.03125\t-0.15892 -0.12344\t0.36246 \n128  \t2.19540  2.10132 \t0.25761  0.28376 \t0.63081  0.57202 \t0.53120  0.49491 \t0.10775  0.09990 \t-0.07457 -0.13641\t-0.17256 -0.18641\t0.22744 \n256  \t2.07995  1.96360 \t0.26871  0.27990 \t0.44579  0.32437 \t0.41527  0.33919 \t0.13641  0.15522 \t-0.03416 0.00656 \t-0.08444 0.00438 \t0.16745 \n512  \t1.97539  1.87042 \t0.27250  0.27631 \t0.30818  0.19422 \t0.30740  0.21807 \t0.07646  0.02680 \t0.23854  0.51230 \t0.25579  0.59734 \t0.12871 \n1024 \t1.89946  1.82339 \t0.27213  0.27176 \t0.22603  0.15095 \t0.23870  0.17590 \t0.04459  0.01546 \t0.52386  0.80975 \t0.58355  0.91195 \t0.10064 \n1499 \t1.86457  1.78928 \t0.27321  0.27552 \t0.20026  0.14709 \t0.21992  0.18118 \t0.03003  0.00001 \t0.64426  0.90406 \t0.71543  1.00000 \t0.08823 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.1625\noptimal const log loss = 0.1985\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.40304  2.40304 \t0.10000  0.10000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.08000 -0.08000\t-0.08000 -0.08000\t1.00000 \n1    \t2.39826  2.39347 \t0.11500  0.13000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00500 0.07000 \t-0.05000 -0.02000\t1.00000 \n2    \t2.39281  2.38191 \t0.13333  0.17000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00333  0.02000 \t-0.05000 -0.05000\t1.00000 \n4    \t2.39141  2.38933 \t0.12800  0.12000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00800  0.01500 \t-0.01400 0.04000 \t1.00000 \n8    \t2.38286  2.37217 \t0.15333  0.18500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01444  0.02250 \t0.00667  0.03250 \t1.00000 \n16   \t2.36596  2.34694 \t0.19471  0.24125 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00176  -0.01250\t-0.00294 -0.01375\t1.00000 \n32   \t2.33526  2.30265 \t0.23515  0.27813 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00788 -0.01813\t-0.00545 -0.00813\t1.00000 \n64   \t2.27565  2.21417 \t0.25611  0.27772 \t0.53642  0.53642 \t0.64041  0.64041 \t0.13970  0.13970 \t-0.01215 -0.01656\t-0.01585 -0.02656\t0.34668 \n128  \t2.18656  2.09608 \t0.26866  0.28140 \t0.41978  0.37786 \t0.52920  0.48923 \t0.10563  0.09338 \t0.03822  0.08937 \t0.05023  0.11734 \t0.22482 \n256  \t2.07740  1.96739 \t0.27283  0.27704 \t0.30649  0.22949 \t0.40431  0.31942 \t0.04842  0.00953 \t0.10249  0.16727 \t0.12685  0.20406 \t0.16667 \n512  \t1.96940  1.86098 \t0.27211  0.27138 \t0.24639  0.19592 \t0.31097  0.23259 \t0.02763  0.01017 \t-0.00637 -0.11566\t-0.00569 -0.13875\t0.12844 \n1024 \t1.88696  1.80435 \t0.27057  0.26904 \t0.18046  0.11980 \t0.22417  0.14432 \t0.03646  0.04458 \t0.39916  0.80549 \t0.44970  0.90598 \t0.10054 \n1499 \t1.85625  1.78999 \t0.27190  0.27477 \t0.15599  0.10535 \t0.19277  0.12778 \t0.02463  0.00015 \t0.55964  0.90594 \t0.62396  1.00000 \t0.08817 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.1625\noptimal const log loss = 0.1985\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.40902  2.40902 \t0.06000  0.06000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.07000 -0.07000\t0.00000  0.00000 \t1.00000 \n1    \t2.40191  2.39480 \t0.07000  0.08000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01500 0.04000 \t0.00000  0.00000 \t1.00000 \n2    \t2.39820  2.39079 \t0.07000  0.07000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.02333 -0.04000\t0.00000  0.00000 \t1.00000 \n4    \t2.38888  2.37489 \t0.12000  0.19500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00400 0.02500 \t0.00000  0.00000 \t1.00000 \n8    \t2.37976  2.36836 \t0.14889  0.18500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01222 -0.02250\t0.00000  0.00000 \t1.00000 \n16   \t2.36279  2.34369 \t0.19765  0.25250 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01235 -0.01250\t0.00000  0.00000 \t1.00000 \n32   \t2.33439  2.30423 \t0.22545  0.25500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00152 0.01000 \t0.00000  0.00000 \t1.00000 \n64   \t2.28247  2.22892 \t0.23645  0.24779 \t0.49663  0.49663 \t0.64270  0.64270 \t0.14708  0.14708 \t-0.02631 -0.05187\t-0.05138 -0.10438\t0.35163 \n128  \t2.18743  2.09090 \t0.25405  0.27192 \t0.36471  0.31936 \t0.52153  0.47987 \t0.08941  0.06958 \t0.03574  0.09875 \t0.04178  0.13641 \t0.22568 \n256  \t2.07167  1.95501 \t0.26093  0.26787 \t0.27904  0.22148 \t0.40110  0.32019 \t0.04033  0.00735 \t0.10459  0.17398 \t0.12588  0.21062 \t0.16692 \n512  \t1.96259  1.85308 \t0.26799  0.27507 \t0.22947  0.18803 \t0.30560  0.22577 \t0.01841  0.00008 \t0.09712  0.08961 \t0.11635  0.10680 \t0.12853 \n1024 \t1.87474  1.78673 \t0.27346  0.27894 \t0.17053  0.11642 \t0.21844  0.13843 \t0.03003  0.04070 \t0.40161  0.70670 \t0.45410  0.79250 \t0.10057 \n1499 \t1.84980  1.79598 \t0.27467  0.27727 \t0.15962  0.13709 \t0.20173  0.16718 \t0.02129  0.00321 \t0.56057  0.90358 \t0.62697  1.00000 \t0.08819 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.1625\noptimal const log loss = 0.1985\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39458  2.39458 \t0.13000  0.13000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01000 -0.01000\t-0.19000 -0.19000\t1.00000 \n1    \t2.39383  2.39308 \t0.11500  0.10000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01500 -0.02000\t-0.20000 -0.21000\t1.00000 \n2    \t2.38895  2.37920 \t0.12333  0.14000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01333 -0.01000\t-0.18667 -0.16000\t1.00000 \n4    \t2.38163  2.37064 \t0.13200  0.14500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01800 -0.02500\t-0.19600 -0.21000\t1.00000 \n8    \t2.37378  2.36398 \t0.15556  0.18500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00667 0.00750 \t-0.22111 -0.25250\t1.00000 \n16   \t2.36241  2.34960 \t0.19059  0.23000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01118 -0.01625\t-0.21059 -0.19875\t1.00000 \n32   \t2.33175  2.29918 \t0.23061  0.27312 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01061 -0.01000\t-0.21000 -0.20938\t1.00000 \n64   \t2.27673  2.21999 \t0.25455  0.27923 \t0.72403  0.72403 \t0.64270  0.64270 \t0.20919  0.20919 \t-0.04108 -0.07250\t-0.20662 -0.20312\t0.35163 \n128  \t2.19357  2.10910 \t0.26107  0.26769 \t0.52784  0.46040 \t0.53372  0.49625 \t0.13497  0.10946 \t-0.08566 -0.13094\t-0.19116 -0.17547\t0.22568 \n256  \t2.06922  1.94390 \t0.27989  0.29886 \t0.38034  0.28123 \t0.41057  0.32784 \t0.08478  0.05106 \t0.02984  0.14625 \t-0.00257 0.18750 \t0.16692 \n512  \t1.96557  1.86151 \t0.27769  0.27547 \t0.28632  0.20772 \t0.31680  0.23842 \t0.04737  0.01609 \t0.18472  0.34020 \t0.19657  0.39648 \t0.12853 \n1024 \t1.88990  1.81409 \t0.27462  0.27154 \t0.22150  0.16201 \t0.25365  0.19568 \t0.03336  0.02049 \t0.53040  0.87676 \t0.59083  0.98586 \t0.10057 \n1499 \t1.85464  1.77855 \t0.27564  0.27785 \t0.19397  0.13706 \t0.22583  0.16831 \t0.02249  0.00004 \t0.64841  0.90307 \t0.72040  1.00000 \t0.08819 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.1625\noptimal const log loss = 0.1985\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.38823  2.38823 \t0.09000  0.09000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.03000 -0.03000\t0.00000  0.00000 \t1.00000 \n1    \t2.39240  2.39656 \t0.11000  0.13000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.04000  0.11000 \t0.00000  0.00000 \t1.00000 \n2    \t2.39404  2.39733 \t0.11333  0.12000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02333  -0.01000\t0.00000  0.00000 \t1.00000 \n4    \t2.39120  2.38693 \t0.10600  0.09500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01000  -0.01000\t0.00000  0.00000 \t1.00000 \n8    \t2.38230  2.37117 \t0.12778  0.15500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00889  0.00750 \t0.00000  0.00000 \t1.00000 \n16   \t2.36215  2.33948 \t0.18176  0.24250 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00706  0.00500 \t0.00000  0.00000 \t1.00000 \n32   \t2.33048  2.29683 \t0.23091  0.28313 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00091 -0.00937\t0.00000  0.00000 \t1.00000 \n64   \t2.27641  2.22065 \t0.25288  0.27554 \t0.63301  0.63301 \t0.64501  0.64501 \t0.25122  0.25122 \t-0.00415 -0.00750\t-0.00923 -0.01875\t0.35688 \n128  \t2.19922  2.12083 \t0.26088  0.26901 \t0.46102  0.40458 \t0.52487  0.48545 \t0.14665  0.11234 \t-0.13240 -0.26266\t-0.18372 -0.36094\t0.22655 \n256  \t2.07787  1.95557 \t0.26594  0.27104 \t0.33191  0.24617 \t0.40134  0.31931 \t0.08918  0.05102 \t-0.18981 -0.24766\t-0.24650 -0.30977\t0.16718 \n512  \t1.96828  1.85827 \t0.27302  0.28013 \t0.25895  0.19824 \t0.30800  0.23033 \t0.05465  0.02592 \t-0.08099 0.02824 \t-0.10949 0.02805 \t0.12862 \n1024 \t1.88160  1.79475 \t0.27323  0.27344 \t0.20208  0.14999 \t0.23918  0.17613 \t0.04581  0.03770 \t0.34015  0.76211 \t0.37316  0.85676 \t0.10061 \n1499 \t1.85476  1.79684 \t0.27358  0.27432 \t0.17379  0.11538 \t0.20777  0.14291 \t0.03114  0.00085 \t0.51964  0.90697 \t0.57166  1.00000 \t0.08821 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.1625\noptimal const log loss = 0.1985\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.38550  2.38550 \t0.16000  0.16000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.03000  0.03000 \t0.22000  0.22000 \t1.00000 \n1    \t2.38144  2.37738 \t0.16500  0.17000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01500  0.00000 \t0.23500  0.25000 \t1.00000 \n2    \t2.39057  2.40884 \t0.14000  0.09000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  -0.03000\t0.21000  0.16000 \t1.00000 \n4    \t2.39232  2.39494 \t0.11800  0.08500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01600 -0.04000\t0.20800  0.20500 \t1.00000 \n8    \t2.37896  2.36225 \t0.16222  0.21750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00667  0.03500 \t0.21111  0.21500 \t1.00000 \n16   \t2.36176  2.34240 \t0.20588  0.25500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00471 -0.01750\t0.20529  0.19875 \t1.00000 \n32   \t2.32811  2.29236 \t0.24182  0.28000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00576 -0.00687\t0.20758  0.21000 \t1.00000 \n64   \t2.27927  2.22890 \t0.24615  0.25061 \t0.64809  0.64809 \t0.63359  0.63359 \t0.11611  0.11611 \t0.02785  0.06250 \t0.17969  0.15094 \t0.33333 \n128  \t2.19116  2.10167 \t0.26140  0.27689 \t0.46911  0.39640 \t0.51381  0.46516 \t0.10100  0.09486 \t0.14659  0.26719 \t0.27481  0.37141 \t0.22232 \n256  \t2.07660  1.96115 \t0.27021  0.27909 \t0.32622  0.22576 \t0.38590  0.29597 \t0.05677  0.02567 \t0.28907  0.43266 \t0.40342  0.53305 \t0.16590 \n512  \t1.96399  1.85094 \t0.27430  0.27840 \t0.24957  0.18430 \t0.29292  0.21374 \t0.02666  0.00103 \t0.18842  0.08738 \t0.25279  0.10156 \t0.12816 \n1024 \t1.88875  1.81336 \t0.27326  0.27223 \t0.19179  0.13829 \t0.22456  0.16128 \t0.03217  0.03727 \t0.49378  0.79973 \t0.57586  0.89957 \t0.10044 \n1499 \t1.85638  1.78652 \t0.27509  0.27904 \t0.17319  0.13460 \t0.20529  0.16528 \t0.02189  0.00054 \t0.62417  0.90556 \t0.71017  1.00000 \t0.08811 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.1625\noptimal const log loss = 0.1985\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39224  2.39224 \t0.15000  0.15000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.03000  0.03000 \t-0.14000 -0.14000\t1.00000 \n1    \t2.38717  2.38210 \t0.15000  0.15000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.09500  0.16000 \t-0.20000 -0.26000\t1.00000 \n2    \t2.38586  2.38326 \t0.15667  0.17000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.07000  0.02000 \t-0.20667 -0.22000\t1.00000 \n4    \t2.38482  2.38325 \t0.15000  0.14000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.04400  0.00500 \t-0.17600 -0.13000\t1.00000 \n8    \t2.37740  2.36813 \t0.17111  0.19750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01889  -0.01250\t-0.17333 -0.17000\t1.00000 \n16   \t2.36298  2.34676 \t0.21235  0.25875 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00059 -0.02250\t-0.17059 -0.16750\t1.00000 \n32   \t2.33355  2.30228 \t0.23970  0.26875 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00121  0.00312 \t-0.18182 -0.19375\t1.00000 \n64   \t2.28205  2.22894 \t0.24971  0.26004 \t0.83754  0.83754 \t0.64270  0.64270 \t0.19074  0.19074 \t-0.02969 -0.06156\t-0.18708 -0.19250\t0.35163 \n128  \t2.19378  2.10414 \t0.26312  0.27673 \t0.65092  0.58678 \t0.52499  0.48453 \t0.16216  0.15233 \t-0.00636 0.01734 \t-0.08163 0.02547 \t0.22568 \n256  \t2.09523  1.99591 \t0.26243  0.26174 \t0.43802  0.29497 \t0.39137  0.30159 \t0.11124  0.07703 \t0.17300  0.35375 \t0.17455  0.43273 \t0.16692 \n512  \t1.98411  1.87255 \t0.26385  0.26528 \t0.31400  0.21032 \t0.30504  0.23288 \t0.09044  0.07305 \t0.40409  0.63609 \t0.45702  0.74059 \t0.12853 \n1024 \t1.89526  1.80625 \t0.26882  0.27380 \t0.23193  0.15659 \t0.24036  0.18098 \t0.05334  0.01929 \t0.64567  0.88771 \t0.72824  1.00000 \t0.10057 \n1499 \t1.86663  1.80485 \t0.26896  0.26926 \t0.19340  0.11375 \t0.20746  0.13945 \t0.03596  0.00002 \t0.72837  0.90684 \t0.81430  1.00000 \t0.08819 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.3251\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39615  2.39615 \t0.04000  0.04000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.03000  0.03000 \t0.24000  0.24000 \t1.00000 \n1    \t2.39610  2.39606 \t0.04500  0.05000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.03000  0.03000 \t0.21500  0.19000 \t1.00000 \n2    \t2.39360  2.38858 \t0.06667  0.11000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02333  0.01000 \t0.19333  0.15000 \t1.00000 \n4    \t2.39428  2.39530 \t0.09400  0.13500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02000  0.01500 \t0.18000  0.16000 \t1.00000 \n8    \t2.38641  2.37657 \t0.13000  0.17500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01333  0.00500 \t0.18889  0.20000 \t1.00000 \n16   \t2.36823  2.34779 \t0.18529  0.24750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00706 -0.03000\t0.19294  0.19750 \t1.00000 \n32   \t2.33399  2.29761 \t0.23273  0.28312 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00515  0.01813 \t0.19061  0.18812 \t1.00000 \n64   \t2.27950  2.22331 \t0.25023  0.26828 \t0.73578  0.73578 \t0.64965  0.64965 \t0.18834  0.18834 \t0.01846  0.03219 \t0.16692  0.14250 \t0.36840 \n128  \t2.19466  2.10849 \t0.26206  0.27407 \t0.52949  0.46824 \t0.55105  0.52178 \t0.14995  0.13856 \t0.09984  0.18250 \t0.21101  0.25578 \t0.22834 \n256  \t2.08983  1.98418 \t0.26570  0.26938 \t0.41374  0.33869 \t0.46510  0.40937 \t0.08259  0.03891 \t0.24381  0.38891 \t0.34405  0.47813 \t0.16771 \n512  \t1.96975  1.84920 \t0.26955  0.27342 \t0.32491  0.25170 \t0.37656  0.30358 \t0.07144  0.06225 \t0.44565  0.64828 \t0.54749  0.75172 \t0.12880 \n1024 \t1.89307  1.81624 \t0.26705  0.26454 \t0.26868  0.21738 \t0.32889  0.28541 \t0.03508  0.00191 \t0.66687  0.88852 \t0.77352  1.00000 \t0.10068 \n1499 \t1.86196  1.79481 \t0.26809  0.27033 \t0.23586  0.16821 \t0.29468  0.22417 \t0.02362  0.00001 \t0.74201  0.90415 \t0.84524  1.00000 \t0.08825 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.3251\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.40226  2.40226 \t0.08000  0.08000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01000  0.01000 \t-0.11000 -0.11000\t1.00000 \n1    \t2.39861  2.39496 \t0.09500  0.11000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01000  0.01000 \t-0.15000 -0.19000\t1.00000 \n2    \t2.39846  2.39815 \t0.08667  0.07000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02333  0.05000 \t-0.17333 -0.22000\t1.00000 \n4    \t2.39333  2.38565 \t0.09600  0.11000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00200 -0.04000\t-0.20400 -0.25000\t1.00000 \n8    \t2.38228  2.36845 \t0.12778  0.16750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00444 -0.00750\t-0.21000 -0.21750\t1.00000 \n16   \t2.36367  2.34275 \t0.19588  0.27250 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00588 -0.00750\t-0.20353 -0.19625\t1.00000 \n32   \t2.33595  2.30649 \t0.23091  0.26813 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00212 0.00187 \t-0.20030 -0.19688\t1.00000 \n64   \t2.28402  2.23046 \t0.25051  0.27073 \t0.43752  0.43752 \t0.64501  0.64501 \t0.09831  0.09831 \t0.00969  0.02187 \t-0.12569 -0.04875\t0.35688 \n128  \t2.19491  2.10442 \t0.26805  0.28585 \t0.37911  0.35994 \t0.54385  0.51066 \t0.07711  0.07016 \t0.05605  0.10313 \t0.00217  0.13203 \t0.22655 \n256  \t2.08877  1.98179 \t0.27025  0.27247 \t0.35033  0.33121 \t0.45881  0.40234 \t0.03543  0.00775 \t0.11533  0.17508 \t0.10615  0.21094 \t0.16718 \n512  \t1.98081  1.87242 \t0.26930  0.26835 \t0.29417  0.24744 \t0.37127  0.29843 \t0.04994  0.06202 \t0.36125  0.60812 \t0.40288  0.70078 \t0.12862 \n1024 \t1.89419  1.80741 \t0.27637  0.28346 \t0.26767  0.24339 \t0.34249  0.31612 \t0.02575  0.00359 \t0.62247  0.88420 \t0.70115  1.00000 \t0.10061 \n1499 \t1.86222  1.79323 \t0.27386  0.26845 \t0.23453  0.16609 \t0.30554  0.22923 \t0.01735  0.00000 \t0.71271  0.90743 \t0.79579  1.00000 \t0.08821 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.3251\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39382  2.39382 \t0.12000  0.12000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02000  0.02000 \t0.00000  0.00000 \t1.00000 \n1    \t2.40494  2.41606 \t0.09000  0.06000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.04500  0.07000 \t0.00000  0.00000 \t1.00000 \n2    \t2.40246  2.39749 \t0.10333  0.13000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01667  -0.04000\t0.00000  0.00000 \t1.00000 \n4    \t2.39620  2.38681 \t0.12200  0.15000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00400 -0.03500\t0.00000  0.00000 \t1.00000 \n8    \t2.38900  2.38001 \t0.14444  0.17250 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01556  0.04000 \t0.00000  0.00000 \t1.00000 \n16   \t2.37701  2.36351 \t0.17765  0.21500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00118  -0.01500\t0.00000  0.00000 \t1.00000 \n32   \t2.34626  2.31358 \t0.22606  0.27750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00667  0.01250 \t0.00000  0.00000 \t1.00000 \n64   \t2.28954  2.23106 \t0.24763  0.26987 \t0.64711  0.64711 \t0.64448  0.64448 \t0.17713  0.17713 \t-0.03231 -0.07250\t-0.06200 -0.12594\t0.34668 \n128  \t2.20315  2.11540 \t0.25939  0.27133 \t0.50907  0.45946 \t0.55086  0.51722 \t0.13802  0.12397 \t-0.14713 -0.26375\t-0.20682 -0.35391\t0.22482 \n256  \t2.09132  1.97862 \t0.26989  0.28047 \t0.42040  0.36013 \t0.46721  0.41035 \t0.08044  0.04130 \t-0.14167 -0.13617\t-0.18696 -0.16695\t0.16667 \n512  \t1.97898  1.86621 \t0.27075  0.27161 \t0.34614  0.28377 \t0.39992  0.34340 \t0.07253  0.06590 \t0.23380  0.61074 \t0.26142  0.71156 \t0.12844 \n1024 \t1.90319  1.82724 \t0.26854  0.26633 \t0.26367  0.18780 \t0.31671  0.24016 \t0.04037  0.01078 \t0.56047  0.88777 \t0.63035  1.00000 \t0.10054 \n1499 \t1.87195  1.80453 \t0.27345  0.28405 \t0.23197  0.16637 \t0.28667  0.22451 \t0.02723  0.00003 \t0.66919  0.90379 \t0.74741  1.00000 \t0.08817 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.3251\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.40005  2.40005 \t0.08000  0.08000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.02000 -0.02000\t-0.18000 -0.18000\t1.00000 \n1    \t2.39923  2.39841 \t0.08000  0.08000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01500  0.05000 \t-0.18500 -0.19000\t1.00000 \n2    \t2.39682  2.39202 \t0.12000  0.20000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00333  -0.02000\t-0.19667 -0.22000\t1.00000 \n4    \t2.39608  2.39497 \t0.11600  0.11000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02800  0.06500 \t-0.18400 -0.16500\t1.00000 \n8    \t2.38640  2.37431 \t0.14667  0.18500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01111  -0.01000\t-0.18333 -0.18250\t1.00000 \n16   \t2.36949  2.35046 \t0.17647  0.21000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01176  0.01250 \t-0.19353 -0.20500\t1.00000 \n32   \t2.34109  2.31092 \t0.21030  0.24625 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00333  -0.00562\t-0.19333 -0.19313\t1.00000 \n64   \t2.28954  2.23638 \t0.23302  0.25644 \t0.83122  0.83122 \t0.64965  0.64965 \t0.13367  0.13367 \t-0.01615 -0.03625\t-0.16708 -0.14000\t0.36840 \n128  \t2.19800  2.10504 \t0.25804  0.28346 \t0.66543  0.61622 \t0.56318  0.53751 \t0.11080  0.10401 \t-0.07814 -0.14109\t-0.18116 -0.19547\t0.22834 \n256  \t2.08329  1.96768 \t0.27058  0.28321 \t0.50465  0.40038 \t0.47163  0.41227 \t0.10885  0.10759 \t-0.05210 -0.02586\t-0.10809 -0.03445\t0.16771 \n512  \t1.97844  1.87318 \t0.27398  0.27739 \t0.37322  0.26490 \t0.38025  0.30493 \t0.06375  0.02658 \t0.33567  0.72496 \t0.36764  0.84523 \t0.12880 \n1024 \t1.89988  1.82116 \t0.27341  0.27285 \t0.28921  0.21258 \t0.32261  0.27003 \t0.03098  0.00108 \t0.61094  0.88674 \t0.68351  1.00000 \t0.10068 \n1499 \t1.86479  1.78908 \t0.27414  0.27570 \t0.26445  0.21341 \t0.31276  0.29248 \t0.02086  0.00000 \t0.70374  0.90400 \t0.78373  1.00000 \t0.08825 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.3251\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.40211  2.40211 \t0.10000  0.10000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.08000 -0.08000\t-0.08000 -0.08000\t1.00000 \n1    \t2.39798  2.39384 \t0.11500  0.13000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00500 0.07000 \t-0.05000 -0.02000\t1.00000 \n2    \t2.39270  2.38214 \t0.13000  0.16000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00333  0.02000 \t-0.05000 -0.05000\t1.00000 \n4    \t2.39177  2.39038 \t0.12400  0.11500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00800  0.01500 \t-0.01400 0.04000 \t1.00000 \n8    \t2.38306  2.37217 \t0.15111  0.18500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01444  0.02250 \t0.00667  0.03250 \t1.00000 \n16   \t2.36672  2.34835 \t0.18706  0.22750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00176  -0.01250\t-0.00294 -0.01375\t1.00000 \n32   \t2.33684  2.30509 \t0.23212  0.28000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00788 -0.01813\t-0.00545 -0.00813\t1.00000 \n64   \t2.27683  2.21494 \t0.25774  0.28415 \t0.56724  0.56724 \t0.64678  0.64678 \t0.13185  0.13185 \t-0.01462 -0.02156\t-0.01908 -0.03313\t0.35688 \n128  \t2.18651  2.09479 \t0.27100  0.28448 \t0.47849  0.44937 \t0.55916  0.53041 \t0.10481  0.09593 \t0.03837  0.09219 \t0.05062  0.12141 \t0.22655 \n256  \t2.07839  1.96942 \t0.27578  0.28060 \t0.38682  0.32595 \t0.45945  0.39323 \t0.04752  0.00949 \t0.10257  0.16727 \t0.12704  0.20406 \t0.16718 \n512  \t1.96942  1.86002 \t0.27325  0.27071 \t0.30911  0.24446 \t0.37059  0.29665 \t0.05717  0.06520 \t0.42031  0.73930 \t0.49121  0.85680 \t0.12862 \n1024 \t1.88637  1.80317 \t0.27218  0.27111 \t0.24967  0.19522 \t0.30842  0.25148 \t0.02796  0.00121 \t0.65426  0.88867 \t0.74536  1.00000 \t0.10061 \n1499 \t1.85579  1.78979 \t0.27309  0.27505 \t0.22904  0.18643 \t0.28975  0.25118 \t0.01884  0.00000 \t0.73393  0.90583 \t0.82599  1.00000 \t0.08821 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.3251\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.40795  2.40795 \t0.06000  0.06000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.07000 -0.07000\t0.00000  0.00000 \t1.00000 \n1    \t2.40173  2.39552 \t0.06500  0.07000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01500 0.04000 \t0.00000  0.00000 \t1.00000 \n2    \t2.39822  2.39118 \t0.06667  0.07000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.02333 -0.04000\t0.00000  0.00000 \t1.00000 \n4    \t2.38898  2.37512 \t0.11800  0.19500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00400 0.02500 \t0.00000  0.00000 \t1.00000 \n8    \t2.37988  2.36852 \t0.14556  0.18000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01222 -0.02250\t0.00000  0.00000 \t1.00000 \n16   \t2.36315  2.34432 \t0.19353  0.24750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01235 -0.01250\t0.00000  0.00000 \t1.00000 \n32   \t2.33529  2.30569 \t0.22333  0.25500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00152 0.01000 \t0.00000  0.00000 \t1.00000 \n64   \t2.28442  2.23197 \t0.23873  0.25461 \t0.49290  0.49290 \t0.64501  0.64501 \t0.14509  0.14509 \t-0.00354 -0.00562\t-0.01338 -0.02719\t0.35688 \n128  \t2.18931  2.09271 \t0.25371  0.26893 \t0.41188  0.38529 \t0.54783  0.51594 \t0.08817  0.06950 \t0.04907  0.10250 \t0.06465  0.14391 \t0.22655 \n256  \t2.07458  1.95895 \t0.26062  0.26758 \t0.35438  0.31620 \t0.45427  0.39213 \t0.03903  0.00640 \t0.11128  0.17398 \t0.13735  0.21062 \t0.16718 \n512  \t1.96673  1.85845 \t0.26825  0.27591 \t0.31866  0.28894 \t0.39369  0.34330 \t0.05594  0.07001 \t0.40865  0.70719 \t0.48027  0.82453 \t0.12862 \n1024 \t1.87836  1.78981 \t0.27285  0.27746 \t0.24700  0.18136 \t0.30767  0.22887 \t0.02771  0.00184 \t0.64840  0.88861 \t0.73988  1.00000 \t0.10061 \n1499 \t1.85220  1.79574 \t0.27436  0.27762 \t0.23314  0.20451 \t0.29752  0.27655 \t0.01867  0.00000 \t0.72919  0.90354 \t0.82225  1.00000 \t0.08821 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.3251\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39485  2.39485 \t0.13000  0.13000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01000 -0.01000\t-0.19000 -0.19000\t1.00000 \n1    \t2.39397  2.39308 \t0.11500  0.10000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01500 -0.02000\t-0.20000 -0.21000\t1.00000 \n2    \t2.38933  2.38005 \t0.12333  0.14000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01333 -0.01000\t-0.18667 -0.16000\t1.00000 \n4    \t2.38155  2.36989 \t0.13200  0.14500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01800 -0.02500\t-0.19600 -0.21000\t1.00000 \n8    \t2.37377  2.36403 \t0.15667  0.18750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00667 0.00750 \t-0.22111 -0.25250\t1.00000 \n16   \t2.36254  2.34991 \t0.19000  0.22750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01118 -0.01625\t-0.21059 -0.19875\t1.00000 \n32   \t2.33248  2.30054 \t0.23000  0.27250 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01061 -0.01000\t-0.21000 -0.20938\t1.00000 \n64   \t2.27848  2.22279 \t0.25511  0.28101 \t0.72938  0.72938 \t0.64998  0.64998 \t0.20710  0.20710 \t-0.03862 -0.06750\t-0.20662 -0.20312\t0.36246 \n128  \t2.19552  2.11127 \t0.26466  0.27435 \t0.56807  0.51767 \t0.56334  0.53627 \t0.13350  0.11050 \t-0.08798 -0.13812\t-0.19736 -0.18797\t0.22744 \n256  \t2.07169  1.94688 \t0.28147  0.29841 \t0.44478  0.36386 \t0.46739  0.40442 \t0.07582  0.03797 \t0.03502  0.15898 \t0.00241  0.20375 \t0.16745 \n512  \t1.96652  1.86095 \t0.27762  0.27377 \t0.35106  0.27345 \t0.38622  0.31900 \t0.05203  0.03232 \t0.32195  0.61000 \t0.35509  0.70914 \t0.12871 \n1024 \t1.89038  1.81408 \t0.27424  0.27085 \t0.28125  0.21744 \t0.33240  0.28320 \t0.02530  0.00087 \t0.60528  0.88916 \t0.67723  1.00000 \t0.10064 \n1499 \t1.85473  1.77780 \t0.27579  0.27915 \t0.25247  0.19307 \t0.30669  0.25366 \t0.01704  0.00001 \t0.69957  0.90303 \t0.77944  1.00000 \t0.08823 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.3251\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.38912  2.38912 \t0.09000  0.09000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.03000 -0.03000\t0.00000  0.00000 \t1.00000 \n1    \t2.39284  2.39656 \t0.11000  0.13000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.04000  0.11000 \t0.00000  0.00000 \t1.00000 \n2    \t2.39455  2.39796 \t0.11000  0.11000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02333  -0.01000\t0.00000  0.00000 \t1.00000 \n4    \t2.39148  2.38689 \t0.10200  0.09000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01000  -0.01000\t0.00000  0.00000 \t1.00000 \n8    \t2.38255  2.37139 \t0.12333  0.15000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00889  0.00750 \t0.00000  0.00000 \t1.00000 \n16   \t2.36283  2.34065 \t0.17824  0.24000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00706  0.00500 \t0.00000  0.00000 \t1.00000 \n32   \t2.33128  2.29776 \t0.22879  0.28250 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00091 -0.00937\t0.00000  0.00000 \t1.00000 \n64   \t2.27720  2.22142 \t0.25241  0.27677 \t0.63580  0.63580 \t0.64732  0.64732 \t0.25695  0.25695 \t-0.00200 -0.00313\t-0.00585 -0.01187\t0.36246 \n128  \t2.20104  2.12370 \t0.26026  0.26823 \t0.50484  0.46392 \t0.55442  0.52539 \t0.14580  0.11106 \t-0.12845 -0.25688\t-0.17868 -0.35422\t0.22744 \n256  \t2.08596  1.96998 \t0.25933  0.25839 \t0.40521  0.33982 \t0.45932  0.39691 \t0.08338  0.04243 \t-0.14498 -0.16164\t-0.19058 -0.20258\t0.16745 \n512  \t1.97219  1.85796 \t0.27155  0.28382 \t0.32637  0.26108 \t0.37615  0.30727 \t0.07306  0.06450 \t0.25320  0.65293 \t0.28285  0.75813 \t0.12871 \n1024 \t1.88316  1.79397 \t0.27265  0.27375 \t0.26602  0.21086 \t0.32137  0.27129 \t0.03546  0.00109 \t0.57068  0.88879 \t0.64107  1.00000 \t0.10064 \n1499 \t1.85583  1.79686 \t0.27337  0.27493 \t0.23294  0.16469 \t0.28791  0.21890 \t0.02388  0.00000 \t0.67715  0.90691 \t0.75473  1.00000 \t0.08823 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.3251\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.38550  2.38550 \t0.16000  0.16000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.03000  0.03000 \t0.22000  0.22000 \t1.00000 \n1    \t2.38192  2.37835 \t0.16500  0.17000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01500  0.00000 \t0.23500  0.25000 \t1.00000 \n2    \t2.39104  2.40927 \t0.14000  0.09000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  -0.03000\t0.21000  0.16000 \t1.00000 \n4    \t2.39277  2.39536 \t0.11800  0.08500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01600 -0.04000\t0.20800  0.20500 \t1.00000 \n8    \t2.37959  2.36311 \t0.16222  0.21750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00667  0.03500 \t0.21111  0.21500 \t1.00000 \n16   \t2.36245  2.34318 \t0.20294  0.24875 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00471 -0.01750\t0.20529  0.19875 \t1.00000 \n32   \t2.32993  2.29538 \t0.23970  0.27875 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00576 -0.00687\t0.20758  0.21000 \t1.00000 \n64   \t2.28162  2.23179 \t0.24522  0.25092 \t0.64276  0.64276 \t0.63359  0.63359 \t0.10780  0.10780 \t0.02785  0.06250 \t0.17969  0.15094 \t0.33333 \n128  \t2.19337  2.10374 \t0.26085  0.27672 \t0.49270  0.43173 \t0.52973  0.48754 \t0.09825  0.09437 \t0.15031  0.27469 \t0.28008  0.38203 \t0.22232 \n256  \t2.07874  1.96322 \t0.27156  0.28235 \t0.39216  0.32147 \t0.44049  0.37774 \t0.05638  0.02695 \t0.26619  0.38297 \t0.37595  0.47258 \t0.16590 \n512  \t1.97273  1.86630 \t0.27175  0.27194 \t0.32663  0.27082 \t0.37236  0.31435 \t0.05849  0.06028 \t0.46222  0.65902 \t0.57119  0.76719 \t0.12816 \n1024 \t1.89290  1.81292 \t0.27218  0.27261 \t0.26844  0.21457 \t0.32115  0.27373 \t0.02952  0.00271 \t0.67458  0.88734 \t0.78539  1.00000 \t0.10044 \n1499 \t1.85919  1.78643 \t0.27428  0.27882 \t0.24479  0.19569 \t0.30278  0.26466 \t0.01992  0.00000 \t0.74772  0.90556 \t0.85335  1.00000 \t0.08811 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.3251\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39332  2.39332 \t0.15000  0.15000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.03000  0.03000 \t-0.14000 -0.14000\t1.00000 \n1    \t2.38771  2.38210 \t0.15000  0.15000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.09500  0.16000 \t-0.20000 -0.26000\t1.00000 \n2    \t2.38621  2.38322 \t0.15667  0.17000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.07000  0.02000 \t-0.20667 -0.22000\t1.00000 \n4    \t2.38474  2.38252 \t0.15800  0.16000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.04400  0.00500 \t-0.17600 -0.13000\t1.00000 \n8    \t2.37733  2.36807 \t0.17667  0.20000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01889  -0.01250\t-0.17333 -0.17000\t1.00000 \n16   \t2.36272  2.34628 \t0.21471  0.25750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00059 -0.02250\t-0.17059 -0.16750\t1.00000 \n32   \t2.33360  2.30267 \t0.24061  0.26812 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00121  0.00312 \t-0.18182 -0.19375\t1.00000 \n64   \t2.28254  2.22987 \t0.25017  0.26004 \t0.84337  0.84337 \t0.64388  0.64388 \t0.18161  0.18161 \t-0.02969 -0.06156\t-0.18708 -0.19250\t0.35163 \n128  \t2.19582  2.10775 \t0.26248  0.27498 \t0.67078  0.61145 \t0.55399  0.52308 \t0.16062  0.15341 \t0.00946  0.04922 \t-0.06155 0.06594 \t0.22568 \n256  \t2.09766  1.99873 \t0.26335  0.26421 \t0.48592  0.36173 \t0.44267  0.36789 \t0.10119  0.06126 \t0.17844  0.34875 \t0.18136  0.42617 \t0.16692 \n512  \t1.98522  1.87234 \t0.26529  0.26724 \t0.37468  0.28168 \t0.37675  0.32163 \t0.07814  0.05887 \t0.44357  0.70973 \t0.50355  0.82699 \t0.12853 \n1024 \t1.89575  1.80610 \t0.26907  0.27286 \t0.29573  0.22325 \t0.32598  0.27938 \t0.04011  0.00520 \t0.66542  0.88771 \t0.75153  1.00000 \t0.10057 \n1499 \t1.86694  1.80476 \t0.26927  0.26969 \t0.25495  0.17064 \t0.29422  0.22855 \t0.02703  0.00001 \t0.74187  0.90684 \t0.83021  1.00000 \t0.08819 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.3365\noptimal const log loss = 0.5004\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39690  2.39690 \t0.04000  0.04000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.03000  0.03000 \t0.24000  0.24000 \t1.00000 \n1    \t2.39668  2.39646 \t0.04500  0.05000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.03000  0.03000 \t0.21500  0.19000 \t1.00000 \n2    \t2.39425  2.38939 \t0.06333  0.10000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02333  0.01000 \t0.19333  0.15000 \t1.00000 \n4    \t2.39459  2.39511 \t0.09200  0.13500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02000  0.01500 \t0.18000  0.16000 \t1.00000 \n8    \t2.38668  2.37678 \t0.12889  0.17500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01333  0.00500 \t0.18889  0.20000 \t1.00000 \n16   \t2.36894  2.34899 \t0.18353  0.24500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00706 -0.03000\t0.19294  0.19750 \t1.00000 \n32   \t2.33476  2.29845 \t0.23182  0.28312 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00515  0.01813 \t0.19061  0.18812 \t1.00000 \n64   \t2.28150  2.22657 \t0.24977  0.26828 \t0.73770  0.73770 \t0.65694  0.65694 \t0.18254  0.18254 \t0.01846  0.03219 \t0.16692  0.14250 \t0.36840 \n128  \t2.19810  2.11340 \t0.26062  0.27164 \t0.59235  0.54920 \t0.60495  0.58952 \t0.15582  0.14789 \t0.10806  0.19906 \t0.22132  0.27656 \t0.22834 \n256  \t2.09387  1.98882 \t0.26383  0.26707 \t0.47741  0.40288 \t0.53801  0.49461 \t0.10724  0.07574 \t0.31794  0.52945 \t0.43529  0.65094 \t0.16771 \n512  \t1.97260  1.85085 \t0.27039  0.27698 \t0.40608  0.34729 \t0.49484  0.45926 \t0.06107  0.02301 \t0.55195  0.78687 \t0.67519  0.91602 \t0.12880 \n1024 \t1.89451  1.81628 \t0.26781  0.26522 \t0.33739  0.27474 \t0.45826  0.42489 \t0.02934  0.00039 \t0.72007  0.88852 \t0.83743  1.00000 \t0.10068 \n1499 \t1.86300  1.79501 \t0.26861  0.27033 \t0.30687  0.24396 \t0.43496  0.38695 \t0.01976  0.00001 \t0.77836  0.90415 \t0.88891  1.00000 \t0.08825 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.3365\noptimal const log loss = 0.5004\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.40346  2.40346 \t0.08000  0.08000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01000  0.01000 \t-0.11000 -0.11000\t1.00000 \n1    \t2.39975  2.39605 \t0.09500  0.11000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01000  0.01000 \t-0.15000 -0.19000\t1.00000 \n2    \t2.39915  2.39795 \t0.08667  0.07000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02333  0.05000 \t-0.17333 -0.22000\t1.00000 \n4    \t2.39393  2.38610 \t0.09000  0.09500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00200 -0.04000\t-0.20400 -0.25000\t1.00000 \n8    \t2.38276  2.36878 \t0.12333  0.16500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00444 -0.00750\t-0.21000 -0.21750\t1.00000 \n16   \t2.36454  2.34404 \t0.18882  0.26250 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00588 -0.00750\t-0.20353 -0.19625\t1.00000 \n32   \t2.33768  2.30914 \t0.22727  0.26813 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00212 0.00187 \t-0.20030 -0.19688\t1.00000 \n64   \t2.28669  2.23410 \t0.24867  0.27073 \t0.43822  0.43822 \t0.64501  0.64501 \t0.08493  0.08493 \t0.00969  0.02187 \t-0.12569 -0.04875\t0.35688 \n128  \t2.19959  2.11113 \t0.26545  0.28250 \t0.49020  0.50726 \t0.60204  0.58795 \t0.09031  0.09207 \t0.14163  0.27562 \t0.11868  0.36688 \t0.22655 \n256  \t2.09257  1.98471 \t0.26932  0.27322 \t0.45185  0.42638 \t0.55149  0.51792 \t0.07878  0.07112 \t0.40054  0.66148 \t0.46564  0.81531 \t0.16718 \n512  \t1.98098  1.86895 \t0.27008  0.27085 \t0.37696  0.31465 \t0.48431  0.42841 \t0.05256  0.03075 \t0.62865  0.85766 \t0.73230  1.00000 \t0.12862 \n1024 \t1.89405  1.80696 \t0.27683  0.28360 \t0.33393  0.29452 \t0.46735  0.45182 \t0.02523  0.00020 \t0.75630  0.88420 \t0.86602  1.00000 \t0.10061 \n1499 \t1.86215  1.79331 \t0.27410  0.26821 \t0.30190  0.23575 \t0.43965  0.38244 \t0.01700  0.00000 \t0.80416  0.90743 \t0.90845  1.00000 \t0.08821 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.3365\noptimal const log loss = 0.5004\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39118  2.39118 \t0.12000  0.12000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02000  0.02000 \t0.00000  0.00000 \t1.00000 \n1    \t2.40009  2.40900 \t0.10500  0.09000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.04500  0.07000 \t0.00000  0.00000 \t1.00000 \n2    \t2.39975  2.39907 \t0.10667  0.11000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01667  -0.04000\t0.00000  0.00000 \t1.00000 \n4    \t2.39402  2.38542 \t0.12800  0.16000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00400 -0.03500\t0.00000  0.00000 \t1.00000 \n8    \t2.38831  2.38117 \t0.14778  0.17250 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01556  0.04000 \t0.00000  0.00000 \t1.00000 \n16   \t2.37606  2.36229 \t0.18118  0.21875 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00118  -0.01500\t0.00000  0.00000 \t1.00000 \n32   \t2.34555  2.31312 \t0.22788  0.27750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00667  0.01250 \t0.00000  0.00000 \t1.00000 \n64   \t2.29001  2.23274 \t0.24870  0.27016 \t0.67450  0.67450 \t0.65657  0.65657 \t0.16105  0.16105 \t-0.02800 -0.06375\t-0.05200 -0.10563\t0.34668 \n128  \t2.20625  2.12119 \t0.25838  0.26822 \t0.60339  0.57784 \t0.61955  0.60625 \t0.13037  0.11934 \t-0.03814 -0.04844\t-0.05938 -0.06687\t0.22482 \n256  \t2.09877  1.99046 \t0.26419  0.27005 \t0.49105  0.41469 \t0.54237  0.48991 \t0.11960  0.11229 \t0.19136  0.42266 \t0.22798  0.51758 \t0.16667 \n512  \t1.98676  1.87430 \t0.26851  0.27285 \t0.40760  0.33751 \t0.49514  0.45548 \t0.06990  0.02816 \t0.49579  0.80141 \t0.58158  0.93656 \t0.12844 \n1024 \t1.90720  1.82749 \t0.26770  0.26689 \t0.33153  0.26155 \t0.44583  0.40047 \t0.03377  0.00053 \t0.69159  0.88777 \t0.79059  1.00000 \t0.10054 \n1499 \t1.87476  1.80475 \t0.27288  0.28405 \t0.30257  0.24265 \t0.42852  0.39269 \t0.02277  0.00001 \t0.75879  0.90379 \t0.85690  1.00000 \t0.08817 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.3365\noptimal const log loss = 0.5004\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39990  2.39990 \t0.08000  0.08000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.02000 -0.02000\t-0.18000 -0.18000\t1.00000 \n1    \t2.40038  2.40087 \t0.08000  0.08000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01500  0.05000 \t-0.18500 -0.19000\t1.00000 \n2    \t2.39811  2.39355 \t0.12000  0.20000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00333  -0.02000\t-0.19667 -0.22000\t1.00000 \n4    \t2.39725  2.39597 \t0.11400  0.10500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02800  0.06500 \t-0.18400 -0.16500\t1.00000 \n8    \t2.38823  2.37696 \t0.13333  0.15750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01111  -0.01000\t-0.18333 -0.18250\t1.00000 \n16   \t2.37124  2.35211 \t0.16706  0.20500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01176  0.01250 \t-0.19353 -0.20500\t1.00000 \n32   \t2.34229  2.31153 \t0.20727  0.25000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00333  -0.00562\t-0.19333 -0.19313\t1.00000 \n64   \t2.29084  2.23778 \t0.23387  0.26130 \t0.83013  0.83013 \t0.66412  0.66412 \t0.12973  0.12973 \t-0.02046 -0.04500\t-0.18585 -0.17813\t0.38891 \n128  \t2.19967  2.10708 \t0.26312  0.29282 \t0.70276  0.67092 \t0.62210  0.61160 \t0.11301  0.10883 \t-0.06628 -0.11281\t-0.17078 -0.15547\t0.23112 \n256  \t2.08579  1.97102 \t0.26881  0.27455 \t0.58123  0.50527 \t0.57141  0.53973 \t0.12481  0.13218 \t-0.00432 0.05812 \t-0.05222 0.06727 \t0.16851 \n512  \t1.97954  1.87288 \t0.27275  0.27670 \t0.45916  0.35999 \t0.51551  0.47008 \t0.06661  0.01932 \t0.42462  0.85523 \t0.47287  1.00000 \t0.12908 \n1024 \t1.90033  1.82097 \t0.27255  0.27235 \t0.36419  0.27812 \t0.46611  0.42134 \t0.03176  0.00018 \t0.65533  0.88648 \t0.73618  1.00000 \t0.10078 \n1499 \t1.86496  1.78863 \t0.27364  0.27601 \t0.33180  0.26524 \t0.45768  0.44037 \t0.02138  0.00005 \t0.73405  0.90394 \t0.81972  1.00000 \t0.08831 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.3365\noptimal const log loss = 0.5004\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39957  2.39957 \t0.11000  0.11000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.08000 -0.08000\t-0.08000 -0.08000\t1.00000 \n1    \t2.39671  2.39384 \t0.12000  0.13000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00500 0.07000 \t-0.05000 -0.02000\t1.00000 \n2    \t2.39130  2.38050 \t0.13667  0.17000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00333  0.02000 \t-0.05000 -0.05000\t1.00000 \n4    \t2.39001  2.38806 \t0.12800  0.11500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00800  0.01500 \t-0.01400 0.04000 \t1.00000 \n8    \t2.38173  2.37138 \t0.15444  0.18750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01444  0.02250 \t0.00667  0.03250 \t1.00000 \n16   \t2.36563  2.34751 \t0.19118  0.23250 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00176  -0.01250\t-0.00294 -0.01375\t1.00000 \n32   \t2.33581  2.30412 \t0.23394  0.27938 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00788 -0.01813\t-0.00545 -0.00813\t1.00000 \n64   \t2.27643  2.21521 \t0.26127  0.28946 \t0.66980  0.66980 \t0.67748  0.67748 \t0.13876  0.13876 \t-0.01046 -0.01313\t-0.01585 -0.02656\t0.36246 \n128  \t2.18880  2.09980 \t0.26814  0.27511 \t0.56797  0.53614 \t0.60734  0.58542 \t0.12383  0.11916 \t0.14085  0.29453 \t0.18969  0.39844 \t0.22744 \n256  \t2.08173  1.97382 \t0.27232  0.27654 \t0.48214  0.42582 \t0.54746  0.50816 \t0.09068  0.06893 \t0.40774  0.67672 \t0.50953  0.83188 \t0.16745 \n512  \t1.97203  1.86190 \t0.27148  0.27064 \t0.39124  0.31596 \t0.48265  0.42899 \t0.05287  0.02155 \t0.63253  0.85820 \t0.75429  1.00000 \t0.12871 \n1024 \t1.88781  1.80342 \t0.27156  0.27163 \t0.32904  0.27218 \t0.44949  0.41918 \t0.02537  0.00024 \t0.76043  0.88857 \t0.87702  1.00000 \t0.10064 \n1499 \t1.85667  1.78948 \t0.27264  0.27498 \t0.30170  0.24530 \t0.43186  0.39547 \t0.01709  0.00002 \t0.80647  0.90583 \t0.91597  1.00000 \t0.08823 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.3365\noptimal const log loss = 0.5004\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.40728  2.40728 \t0.06000  0.06000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.07000 -0.07000\t0.00000  0.00000 \t1.00000 \n1    \t2.40226  2.39723 \t0.05500  0.05000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01500 0.04000 \t0.00000  0.00000 \t1.00000 \n2    \t2.39853  2.39107 \t0.06000  0.07000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.02333 -0.04000\t0.00000  0.00000 \t1.00000 \n4    \t2.38904  2.37481 \t0.11400  0.19500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00400 0.02500 \t0.00000  0.00000 \t1.00000 \n8    \t2.37990  2.36848 \t0.14667  0.18750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01222 -0.02250\t0.00000  0.00000 \t1.00000 \n16   \t2.36313  2.34427 \t0.19412  0.24750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01235 -0.01250\t0.00000  0.00000 \t1.00000 \n32   \t2.33501  2.30513 \t0.22364  0.25500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00152 0.01000 \t0.00000  0.00000 \t1.00000 \n64   \t2.28483  2.23308 \t0.23897  0.25477 \t0.54643  0.54643 \t0.65879  0.65879 \t0.14497  0.14497 \t0.00600  0.01375 \t0.00385  0.00781 \t0.35688 \n128  \t2.19093  2.09557 \t0.25383  0.26893 \t0.52218  0.51422 \t0.60608  0.58879 \t0.08941  0.07117 \t0.05388  0.10250 \t0.07333  0.14391 \t0.22655 \n256  \t2.07312  1.95439 \t0.26247  0.27118 \t0.43467  0.37656 \t0.51607  0.45629 \t0.09249  0.09455 \t0.32568  0.59961 \t0.40148  0.73219 \t0.16718 \n512  \t1.96354  1.85353 \t0.27025  0.27805 \t0.39081  0.35432 \t0.48975  0.46786 \t0.06065  0.03416 \t0.58893  0.85320 \t0.70016  1.00000 \t0.12862 \n1024 \t1.87675  1.78978 \t0.27393  0.27761 \t0.33044  0.27513 \t0.44535  0.40467 \t0.02907  0.00015 \t0.73862  0.88861 \t0.84993  1.00000 \t0.10061 \n1499 \t1.85097  1.79536 \t0.27510  0.27762 \t0.30816  0.26216 \t0.43961  0.42777 \t0.01960  0.00002 \t0.79085  0.90354 \t0.89745  1.00000 \t0.08821 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.3365\noptimal const log loss = 0.5004\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39477  2.39477 \t0.13000  0.13000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01000 -0.01000\t-0.19000 -0.19000\t1.00000 \n1    \t2.39416  2.39355 \t0.11500  0.10000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01500 -0.02000\t-0.20000 -0.21000\t1.00000 \n2    \t2.38974  2.38091 \t0.12333  0.14000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01333 -0.01000\t-0.18667 -0.16000\t1.00000 \n4    \t2.38200  2.37040 \t0.13200  0.14500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01800 -0.02500\t-0.19600 -0.21000\t1.00000 \n8    \t2.37400  2.36400 \t0.15889  0.19250 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00667 0.00750 \t-0.22111 -0.25250\t1.00000 \n16   \t2.36264  2.34985 \t0.19059  0.22625 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01118 -0.01625\t-0.21059 -0.19875\t1.00000 \n32   \t2.33266  2.30081 \t0.23030  0.27250 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01061 -0.01000\t-0.21000 -0.20938\t1.00000 \n64   \t2.27850  2.22265 \t0.25513  0.28072 \t0.74398  0.74398 \t0.65844  0.65844 \t0.20233  0.20233 \t-0.04000 -0.07031\t-0.20662 -0.20312\t0.35688 \n128  \t2.19601  2.11224 \t0.26376  0.27253 \t0.61511  0.57283 \t0.60627  0.58915 \t0.13409  0.11170 \t-0.07581 -0.11219\t-0.17907 -0.15109\t0.22655 \n256  \t2.07383  1.95069 \t0.28087  0.29812 \t0.51725  0.45227 \t0.55197  0.51592 \t0.10456  0.08495 \t0.18809  0.45406 \t0.18981  0.56156 \t0.16718 \n512  \t1.96453  1.85481 \t0.28006  0.27924 \t0.41860  0.33653 \t0.49159  0.44134 \t0.05254  0.00926 \t0.52135  0.85590 \t0.59411  1.00000 \t0.12862 \n1024 \t1.88900  1.81332 \t0.27560  0.27113 \t0.34209  0.27200 \t0.45015  0.41220 \t0.02514  0.00004 \t0.70509  0.88920 \t0.79686  1.00000 \t0.10061 \n1499 \t1.85392  1.77823 \t0.27637  0.27804 \t0.31635  0.26317 \t0.43588  0.40640 \t0.01695  0.00002 \t0.76779  0.90307 \t0.86119  1.00000 \t0.08821 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.3365\noptimal const log loss = 0.5004\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39019  2.39019 \t0.09000  0.09000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.03000 -0.03000\t0.00000  0.00000 \t1.00000 \n1    \t2.39338  2.39656 \t0.11000  0.13000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.04000  0.11000 \t0.00000  0.00000 \t1.00000 \n2    \t2.39490  2.39796 \t0.11000  0.11000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02333  -0.01000\t0.00000  0.00000 \t1.00000 \n4    \t2.39204  2.38776 \t0.09400  0.07000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01000  -0.01000\t0.00000  0.00000 \t1.00000 \n8    \t2.38311  2.37193 \t0.11667  0.14500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00889  0.00750 \t0.00000  0.00000 \t1.00000 \n16   \t2.36327  2.34096 \t0.17765  0.24625 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00706  0.00500 \t0.00000  0.00000 \t1.00000 \n32   \t2.33201  2.29880 \t0.22879  0.28313 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00091 -0.00937\t0.00000  0.00000 \t1.00000 \n64   \t2.27965  2.22566 \t0.25022  0.27232 \t0.65119  0.65119 \t0.65303  0.65303 \t0.25427  0.25427 \t0.00154  0.00406 \t0.00000  0.00000 \t0.36840 \n128  \t2.20333  2.12582 \t0.26072  0.27138 \t0.59116  0.57334 \t0.62205  0.61285 \t0.15113  0.12051 \t-0.11488 -0.23313\t-0.15729 -0.31703\t0.22834 \n256  \t2.08862  1.97301 \t0.25988  0.25903 \t0.49726  0.43636 \t0.55506  0.51162 \t0.13829  0.12996 \t0.15887  0.43477 \t0.18541  0.53078 \t0.16771 \n512  \t1.97384  1.85862 \t0.26961  0.27938 \t0.41748  0.35173 \t0.50569  0.46500 \t0.07272  0.01869 \t0.50519  0.85285 \t0.59191  1.00000 \t0.12880 \n1024 \t1.88409  1.79416 \t0.27100  0.27240 \t0.34863  0.28583 \t0.46905  0.43563 \t0.03475  0.00012 \t0.69678  0.88875 \t0.79576  1.00000 \t0.10068 \n1499 \t1.85653  1.79707 \t0.27202  0.27423 \t0.31248  0.23799 \t0.43944  0.37842 \t0.02341  0.00002 \t0.76331  0.90688 \t0.86043  1.00000 \t0.08825 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.3365\noptimal const log loss = 0.5004\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.38740  2.38740 \t0.16000  0.16000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.03000  0.03000 \t0.22000  0.22000 \t1.00000 \n1    \t2.38326  2.37913 \t0.16500  0.17000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01500  0.00000 \t0.23500  0.25000 \t1.00000 \n2    \t2.39207  2.40969 \t0.14000  0.09000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  -0.03000\t0.21000  0.16000 \t1.00000 \n4    \t2.39357  2.39583 \t0.11800  0.08500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01600 -0.04000\t0.20800  0.20500 \t1.00000 \n8    \t2.38020  2.36349 \t0.16111  0.21500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00667  0.03500 \t0.21111  0.21500 \t1.00000 \n16   \t2.36333  2.34435 \t0.20000  0.24375 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00471 -0.01750\t0.20529  0.19875 \t1.00000 \n32   \t2.33082  2.29627 \t0.24061  0.28375 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00576 -0.00687\t0.20758  0.21000 \t1.00000 \n64   \t2.28258  2.23283 \t0.24569  0.25092 \t0.63650  0.63650 \t0.64055  0.64055 \t0.09684  0.09684 \t0.02785  0.06250 \t0.17969  0.15094 \t0.33333 \n128  \t2.19532  2.10670 \t0.26281  0.28021 \t0.55895  0.52744 \t0.58967  0.56899 \t0.09806  0.09856 \t0.15659  0.28734 \t0.28930  0.40062 \t0.22232 \n256  \t2.08218  1.96816 \t0.27183  0.28091 \t0.48440  0.43198 \t0.53954  0.50429 \t0.09385  0.09089 \t0.37735  0.59984 \t0.51125  0.73492 \t0.16590 \n512  \t1.97188  1.86114 \t0.27294  0.27405 \t0.40419  0.33590 \t0.48441  0.43748 \t0.05307  0.01834 \t0.61565  0.85488 \t0.75515  1.00000 \t0.12816 \n1024 \t1.89240  1.81277 \t0.27245  0.27197 \t0.34022  0.28100 \t0.45102  0.42011 \t0.02561  0.00019 \t0.75137  0.88734 \t0.87745  1.00000 \t0.10044 \n1499 \t1.85880  1.78628 \t0.27447  0.27882 \t0.31361  0.25836 \t0.43950  0.41559 \t0.01729  0.00001 \t0.80019  0.90556 \t0.91626  1.00000 \t0.08811 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.3365\noptimal const log loss = 0.5004\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39270  2.39270 \t0.16000  0.16000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.03000  0.03000 \t-0.14000 -0.14000\t1.00000 \n1    \t2.38726  2.38183 \t0.15500  0.15000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.09500  0.16000 \t-0.20000 -0.26000\t1.00000 \n2    \t2.38598  2.38341 \t0.16667  0.19000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.07000  0.02000 \t-0.20667 -0.22000\t1.00000 \n4    \t2.38428  2.38173 \t0.16800  0.17000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.04400  0.00500 \t-0.17600 -0.13000\t1.00000 \n8    \t2.37665  2.36711 \t0.18444  0.20500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01889  -0.01250\t-0.17333 -0.17000\t1.00000 \n16   \t2.36228  2.34611 \t0.21824  0.25625 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00059 -0.02250\t-0.17059 -0.16750\t1.00000 \n32   \t2.33345  2.30282 \t0.24212  0.26750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00121  0.00312 \t-0.18182 -0.19375\t1.00000 \n64   \t2.28283  2.23064 \t0.25094  0.26004 \t0.81338  0.81338 \t0.65378  0.65378 \t0.17304  0.17304 \t-0.02969 -0.06156\t-0.18708 -0.19250\t0.35163 \n128  \t2.19721  2.11024 \t0.26325  0.27574 \t0.68754  0.64428 \t0.61136  0.59678 \t0.16396  0.16084 \t0.01899  0.06844 \t-0.04891 0.09141 \t0.22568 \n256  \t2.10013  2.00228 \t0.26338  0.26353 \t0.53632  0.43471 \t0.52109  0.46043 \t0.11648  0.08458 \t0.19210  0.36656 \t0.19887  0.44859 \t0.16692 \n512  \t1.98669  1.87281 \t0.26382  0.26425 \t0.44182  0.36283 \t0.48983  0.46370 \t0.07082  0.03265 \t0.49390  0.79687 \t0.56322  0.92898 \t0.12853 \n1024 \t1.89626  1.80566 \t0.26857  0.27333 \t0.36295  0.29055 \t0.45946  0.43158 \t0.03410  0.00039 \t0.69061  0.88771 \t0.78140  1.00000 \t0.10057 \n1499 \t1.86725  1.80464 \t0.26893  0.26969 \t0.32271  0.23952 \t0.43537  0.38555 \t0.02298  0.00000 \t0.75909  0.90684 \t0.85062  1.00000 \t0.08819 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.6730\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39466  2.39466 \t0.04000  0.04000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.03000  0.03000 \t0.24000  0.24000 \t1.00000 \n1    \t2.39583  2.39700 \t0.04500  0.05000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.03000  0.03000 \t0.21500  0.19000 \t1.00000 \n2    \t2.39415  2.39079 \t0.06333  0.10000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02333  0.01000 \t0.19333  0.15000 \t1.00000 \n4    \t2.39371  2.39304 \t0.09200  0.13500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02000  0.01500 \t0.18000  0.16000 \t1.00000 \n8    \t2.38545  2.37514 \t0.13889  0.19750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01333  0.00500 \t0.18889  0.20000 \t1.00000 \n16   \t2.36748  2.34726 \t0.18647  0.24000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00706 -0.03000\t0.19294  0.19750 \t1.00000 \n32   \t2.33365  2.29770 \t0.23212  0.28062 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00515  0.01813 \t0.19061  0.18812 \t1.00000 \n64   \t2.28098  2.22667 \t0.24937  0.26716 \t0.69990  0.69990 \t0.69498  0.69498 \t0.19525  0.19525 \t0.00477  0.00437 \t0.14600  0.10000 \t0.36246 \n128  \t2.19729  2.11229 \t0.25891  0.26859 \t0.61206  0.58460 \t0.68505  0.68195 \t0.15326  0.14013 \t0.16078  0.31922 \t0.28853  0.43328 \t0.22744 \n256  \t2.09703  1.99599 \t0.26161  0.26434 \t0.49745  0.42224 \t0.65509  0.63543 \t0.09041  0.04917 \t0.44844  0.73836 \t0.59864  0.91117 \t0.16745 \n512  \t1.97266  1.84780 \t0.26879  0.27599 \t0.40535  0.32907 \t0.64086  0.62908 \t0.04400  0.00556 \t0.65267  0.85770 \t0.79893  1.00000 \t0.12871 \n1024 \t1.89454  1.81627 \t0.26695  0.26512 \t0.31084  0.22445 \t0.61911  0.59922 \t0.02102  0.00001 \t0.77048  0.88852 \t0.89937  1.00000 \t0.10064 \n1499 \t1.86300  1.79493 \t0.26804  0.27038 \t0.27181  0.19128 \t0.61252  0.59893 \t0.01420  0.00012 \t0.81283  0.90423 \t0.93123  1.00000 \t0.08823 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.6730\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.40441  2.40441 \t0.08000  0.08000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01000  0.01000 \t-0.11000 -0.11000\t1.00000 \n1    \t2.40011  2.39582 \t0.09500  0.11000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01000  0.01000 \t-0.15000 -0.19000\t1.00000 \n2    \t2.39957  2.39850 \t0.08667  0.07000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02333  0.05000 \t-0.17333 -0.22000\t1.00000 \n4    \t2.39457  2.38705 \t0.09000  0.09500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00200 -0.04000\t-0.20400 -0.25000\t1.00000 \n8    \t2.38330  2.36922 \t0.12111  0.16000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00444 -0.00750\t-0.21000 -0.21750\t1.00000 \n16   \t2.36473  2.34384 \t0.18941  0.26625 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00588 -0.00750\t-0.20353 -0.19625\t1.00000 \n32   \t2.33752  2.30860 \t0.22818  0.26938 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00212 0.00187 \t-0.20030 -0.19688\t1.00000 \n64   \t2.28487  2.23057 \t0.24913  0.27073 \t0.65595  0.65595 \t0.68473  0.68473 \t0.08961  0.08961 \t0.00969  0.02187 \t-0.12569 -0.04875\t0.35688 \n128  \t2.19798  2.10975 \t0.26644  0.28401 \t0.62798  0.61880 \t0.68311  0.68258 \t0.10947  0.11598 \t0.14829  0.28906 \t0.12806  0.38578 \t0.22655 \n256  \t2.08878  1.97872 \t0.26997  0.27354 \t0.51669  0.44279 \t0.66571  0.65415 \t0.08725  0.07250 \t0.45113  0.75633 \t0.53214  0.93938 \t0.16718 \n512  \t1.97956  1.86992 \t0.26916  0.26835 \t0.40703  0.31578 \t0.63189  0.60375 \t0.04406  0.00813 \t0.65400  0.85766 \t0.76561  1.00000 \t0.12862 \n1024 \t1.89330  1.80686 \t0.27637  0.28360 \t0.31772  0.23591 \t0.62492  0.61854 \t0.02109  0.00005 \t0.76899  0.88420 \t0.88269  1.00000 \t0.10061 \n1499 \t1.86173  1.79362 \t0.27379  0.26821 \t0.27994  0.20191 \t0.60606  0.56710 \t0.01422  0.00004 \t0.81283  0.90743 \t0.91984  1.00000 \t0.08821 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.6730\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39118  2.39118 \t0.11000  0.11000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02000  0.02000 \t0.00000  0.00000 \t1.00000 \n1    \t2.40018  2.40918 \t0.09500  0.08000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.04500  0.07000 \t0.00000  0.00000 \t1.00000 \n2    \t2.39963  2.39853 \t0.09000  0.08000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01667  -0.04000\t0.00000  0.00000 \t1.00000 \n4    \t2.39307  2.38323 \t0.12600  0.18000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00400 -0.03500\t0.00000  0.00000 \t1.00000 \n8    \t2.38615  2.37750 \t0.15222  0.18500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01556  0.04000 \t0.00000  0.00000 \t1.00000 \n16   \t2.37408  2.36051 \t0.18647  0.22500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00118  -0.01500\t0.00000  0.00000 \t1.00000 \n32   \t2.34335  2.31069 \t0.22970  0.27562 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00667  0.01250 \t0.00000  0.00000 \t1.00000 \n64   \t2.28869  2.23232 \t0.25003  0.27099 \t0.69144  0.69144 \t0.68682  0.68682 \t0.21622  0.21622 \t-0.02262 -0.05281\t-0.04169 -0.08469\t0.35688 \n128  \t2.20512  2.12024 \t0.25612  0.26230 \t0.64229  0.62616 \t0.69511  0.69783 \t0.15424  0.13390 \t0.09380  0.21203 \t0.12047  0.28516 \t0.22655 \n256  \t2.10226  1.99859 \t0.26208  0.26809 \t0.53495  0.46367 \t0.66424  0.64374 \t0.09854  0.06155 \t0.37720  0.66281 \t0.46739  0.81703 \t0.16718 \n512  \t1.98719  1.87166 \t0.26796  0.27386 \t0.41896  0.32246 \t0.64211  0.62369 \t0.04809  0.00611 \t0.61561  0.85496 \t0.73318  1.00000 \t0.12862 \n1024 \t1.90774  1.82813 \t0.26745  0.26695 \t0.31066  0.21145 \t0.61856  0.59699 \t0.02300  0.00002 \t0.75151  0.88768 \t0.86646  1.00000 \t0.10061 \n1499 \t1.87544  1.80576 \t0.27253  0.28348 \t0.27371  0.19741 \t0.60771  0.58529 \t0.01551  0.00002 \t0.79970  0.90368 \t0.90875  1.00000 \t0.08821 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.6730\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39749  2.39749 \t0.08000  0.08000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.02000 -0.02000\t-0.18000 -0.18000\t1.00000 \n1    \t2.40040  2.40332 \t0.07500  0.07000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01500  0.05000 \t-0.18500 -0.19000\t1.00000 \n2    \t2.39917  2.39670 \t0.11333  0.19000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00333  -0.02000\t-0.19667 -0.22000\t1.00000 \n4    \t2.39785  2.39586 \t0.11400  0.11500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02800  0.06500 \t-0.18400 -0.16500\t1.00000 \n8    \t2.38964  2.37937 \t0.13667  0.16500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01111  -0.01000\t-0.18333 -0.18250\t1.00000 \n16   \t2.37251  2.35324 \t0.16824  0.20375 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01176  0.01250 \t-0.19353 -0.20500\t1.00000 \n32   \t2.34342  2.31252 \t0.20848  0.25125 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00333  -0.00562\t-0.19333 -0.19313\t1.00000 \n64   \t2.29127  2.23748 \t0.23283  0.25793 \t0.62616  0.62616 \t0.67877  0.67877 \t0.13157  0.13157 \t-0.00785 -0.01938\t-0.15046 -0.10625\t0.36840 \n128  \t2.20055  2.10842 \t0.25808  0.28372 \t0.67505  0.68956 \t0.69726  0.70275 \t0.13374  0.13438 \t-0.02907 -0.05063\t-0.11465 -0.07828\t0.22834 \n256  \t2.08078  1.96007 \t0.27014  0.28229 \t0.57116  0.50379 \t0.68219  0.67242 \t0.10578  0.08766 \t0.27358  0.57859 \t0.29607  0.71000 \t0.16771 \n512  \t1.97660  1.87201 \t0.27297  0.27581 \t0.43471  0.32225 \t0.65308  0.62908 \t0.05004  0.00409 \t0.56405  0.85566 \t0.64735  1.00000 \t0.12880 \n1024 \t1.89888  1.82101 \t0.27331  0.27365 \t0.32637  0.22756 \t0.62940  0.60781 \t0.02387  0.00001 \t0.72524  0.88674 \t0.82350  1.00000 \t0.10068 \n1499 \t1.86400  1.78875 \t0.27414  0.27592 \t0.28105  0.18764 \t0.62338  0.61098 \t0.01607  0.00000 \t0.78185  0.90400 \t0.87939  1.00000 \t0.08825 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.6730\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.40161  2.40161 \t0.08000  0.08000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.08000 -0.08000\t-0.08000 -0.08000\t1.00000 \n1    \t2.39680  2.39199 \t0.10000  0.12000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00500 0.07000 \t-0.05000 -0.02000\t1.00000 \n2    \t2.39148  2.38085 \t0.12333  0.17000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00333  0.02000 \t-0.05000 -0.05000\t1.00000 \n4    \t2.38976  2.38718 \t0.11800  0.11000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00800  0.01500 \t-0.01400 0.04000 \t1.00000 \n8    \t2.38146  2.37108 \t0.15222  0.19500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01444  0.02250 \t0.00667  0.03250 \t1.00000 \n16   \t2.36436  2.34512 \t0.19235  0.23750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00176  -0.01250\t-0.00294 -0.01375\t1.00000 \n32   \t2.33449  2.30277 \t0.23455  0.27938 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00788 -0.01813\t-0.00545 -0.00813\t1.00000 \n64   \t2.27518  2.21401 \t0.25897  0.28415 \t0.72923  0.72923 \t0.69361  0.69361 \t0.14199  0.14199 \t-0.01462 -0.02156\t-0.01908 -0.03313\t0.35688 \n128  \t2.18808  2.09961 \t0.27082  0.28286 \t0.64014  0.61091 \t0.68444  0.68144 \t0.14762  0.14946 \t0.12651  0.26984 \t0.17062  0.36328 \t0.22655 \n256  \t2.07971  1.97050 \t0.27481  0.27884 \t0.52655  0.45113 \t0.66391  0.65028 \t0.09670  0.06290 \t0.46183  0.79977 \t0.57903  0.99063 \t0.16718 \n512  \t1.97120  1.86226 \t0.27280  0.27078 \t0.40202  0.29841 \t0.64035  0.62075 \t0.04714  0.00591 \t0.65967  0.85828 \t0.78910  1.00000 \t0.12862 \n1024 \t1.88768  1.80400 \t0.27196  0.27111 \t0.30126  0.20896 \t0.62624  0.61332 \t0.02256  0.00005 \t0.77406  0.88867 \t0.89445  1.00000 \t0.10061 \n1499 \t1.85671  1.78987 \t0.27294  0.27505 \t0.26081  0.17725 \t0.61786  0.60056 \t0.01523  0.00009 \t0.81579  0.90583 \t0.92787  1.00000 \t0.08821 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.6730\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.40636  2.40636 \t0.06000  0.06000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.07000 -0.07000\t0.00000  0.00000 \t1.00000 \n1    \t2.40247  2.39858 \t0.04500  0.03000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01500 0.04000 \t0.00000  0.00000 \t1.00000 \n2    \t2.39828  2.38990 \t0.05000  0.06000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.02333 -0.04000\t0.00000  0.00000 \t1.00000 \n4    \t2.38964  2.37669 \t0.10400  0.18500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00400 0.02500 \t0.00000  0.00000 \t1.00000 \n8    \t2.38002  2.36800 \t0.14222  0.19000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01222 -0.02250\t0.00000  0.00000 \t1.00000 \n16   \t2.36292  2.34367 \t0.19176  0.24750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01235 -0.01250\t0.00000  0.00000 \t1.00000 \n32   \t2.33456  2.30443 \t0.22212  0.25437 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00152 0.01000 \t0.00000  0.00000 \t1.00000 \n64   \t2.28415  2.23217 \t0.23769  0.25374 \t0.61878  0.61878 \t0.68579  0.68579 \t0.15001  0.15001 \t-0.00354 -0.00563\t-0.01231 -0.02500\t0.35688 \n128  \t2.18892  2.09221 \t0.25437  0.27131 \t0.60372  0.59877 \t0.68358  0.68286 \t0.14300  0.14070 \t0.20442  0.41562 \t0.26705  0.55078 \t0.22655 \n256  \t2.07173  1.95361 \t0.26560  0.27693 \t0.50635  0.44170 \t0.65209  0.63117 \t0.08793  0.05135 \t0.50537  0.80867 \t0.63210  1.00000 \t0.16718 \n512  \t1.96197  1.85179 \t0.27127  0.27696 \t0.40557  0.32171 \t0.64235  0.63425 \t0.04124  0.00240 \t0.67895  0.85320 \t0.81569  1.00000 \t0.12862 \n1024 \t1.87611  1.79008 \t0.27436  0.27744 \t0.31728  0.23640 \t0.62653  0.61204 \t0.01972  0.00001 \t0.78368  0.88861 \t0.90776  1.00000 \t0.10061 \n1499 \t1.85052  1.79530 \t0.27539  0.27762 \t0.27357  0.18330 \t0.62346  0.61711 \t0.01331  0.00008 \t0.82163  0.90354 \t0.93697  1.00000 \t0.08821 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.6730\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39279  2.39279 \t0.13000  0.13000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01000 -0.01000\t-0.19000 -0.19000\t1.00000 \n1    \t2.39298  2.39318 \t0.12000  0.11000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01500 -0.02000\t-0.20000 -0.21000\t1.00000 \n2    \t2.38966  2.38301 \t0.12667  0.14000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01333 -0.01000\t-0.18667 -0.16000\t1.00000 \n4    \t2.38235  2.37138 \t0.14200  0.16500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01800 -0.02500\t-0.19600 -0.21000\t1.00000 \n8    \t2.37444  2.36455 \t0.16556  0.19500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00667 0.00750 \t-0.22111 -0.25250\t1.00000 \n16   \t2.36273  2.34955 \t0.18824  0.21375 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01118 -0.01625\t-0.21059 -0.19875\t1.00000 \n32   \t2.33229  2.29995 \t0.22970  0.27375 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01061 -0.01000\t-0.21000 -0.20938\t1.00000 \n64   \t2.27800  2.22201 \t0.25096  0.27289 \t0.69438  0.69438 \t0.69101  0.69101 \t0.19163  0.19163 \t-0.04800 -0.08656\t-0.20892 -0.20781\t0.34200 \n128  \t2.19540  2.11150 \t0.26260  0.27443 \t0.64001  0.61962 \t0.69406  0.69520 \t0.14620  0.12916 \t-0.06605 -0.08437\t-0.16101 -0.11234\t0.22398 \n256  \t2.07349  1.95064 \t0.27908  0.29569 \t0.54163  0.47400 \t0.67818  0.66726 \t0.09672  0.06270 \t0.31852  0.70609 \t0.35564  0.87633 \t0.16641 \n512  \t1.96451  1.85511 \t0.27929  0.27950 \t0.42758  0.33135 \t0.65029  0.62675 \t0.04639  0.00392 \t0.58686  0.85625 \t0.67719  1.00000 \t0.12835 \n1024 \t1.88876  1.81285 \t0.27551  0.27172 \t0.32153  0.22376 \t0.62707  0.60567 \t0.02227  0.00003 \t0.73799  0.88941 \t0.83844  1.00000 \t0.10051 \n1499 \t1.85363  1.77783 \t0.27643  0.27843 \t0.27997  0.19387 \t0.62452  0.61922 \t0.01503  0.00002 \t0.79030  0.90318 \t0.88960  1.00000 \t0.08815 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.6730\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39087  2.39087 \t0.09000  0.09000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.03000 -0.03000\t0.00000  0.00000 \t1.00000 \n1    \t2.39381  2.39674 \t0.10500  0.12000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.04000  0.11000 \t0.00000  0.00000 \t1.00000 \n2    \t2.39529  2.39827 \t0.10000  0.09000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.02333  -0.01000\t0.00000  0.00000 \t1.00000 \n4    \t2.39185  2.38668 \t0.10200  0.10500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01000  -0.01000\t0.00000  0.00000 \t1.00000 \n8    \t2.38282  2.37153 \t0.12000  0.14250 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00889  0.00750 \t0.00000  0.00000 \t1.00000 \n16   \t2.36308  2.34087 \t0.18235  0.25250 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00706  0.00500 \t0.00000  0.00000 \t1.00000 \n32   \t2.33204  2.29906 \t0.22970  0.28000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00091 -0.00937\t0.00000  0.00000 \t1.00000 \n64   \t2.27941  2.22513 \t0.25224  0.27548 \t0.71594  0.71594 \t0.69436  0.69436 \t0.24508  0.24508 \t0.00185  0.00469 \t0.00000  0.00000 \t0.36246 \n128  \t2.20217  2.12372 \t0.26186  0.27163 \t0.62343  0.59452 \t0.68784  0.68580 \t0.18260  0.16307 \t0.07597  0.15125 \t0.09868  0.19891 \t0.22744 \n256  \t2.08406  1.96503 \t0.26094  0.26001 \t0.51031  0.43607 \t0.66676  0.65294 \t0.10963  0.06175 \t0.41949  0.76570 \t0.51813  0.94086 \t0.16745 \n512  \t1.97173  1.85896 \t0.27105  0.28121 \t0.40444  0.31677 \t0.65098  0.63791 \t0.05180  0.00390 \t0.63579  0.85293 \t0.75860  1.00000 \t0.12871 \n1024 \t1.88319  1.79448 \t0.27239  0.27374 \t0.30905  0.22186 \t0.63441  0.61926 \t0.02474  0.00001 \t0.76217  0.88879 \t0.87918  1.00000 \t0.10064 \n1499 \t1.85604  1.79745 \t0.27313  0.27470 \t0.26949  0.18786 \t0.61904  0.58735 \t0.01667  0.00002 \t0.80800  0.90691 \t0.91744  1.00000 \t0.08823 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.6730\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.38839  2.38839 \t0.16000  0.16000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.03000  0.03000 \t0.22000  0.22000 \t1.00000 \n1    \t2.38433  2.38028 \t0.16500  0.17000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01500  0.00000 \t0.23500  0.25000 \t1.00000 \n2    \t2.39308  2.41057 \t0.14000  0.09000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  -0.03000\t0.21000  0.16000 \t1.00000 \n4    \t2.39431  2.39616 \t0.12400  0.10000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.01600 -0.04000\t0.20800  0.20500 \t1.00000 \n8    \t2.38086  2.36404 \t0.16889  0.22500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00667  0.03500 \t0.21111  0.21500 \t1.00000 \n16   \t2.36396  2.34494 \t0.20235  0.24000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00471 -0.01750\t0.20529  0.19875 \t1.00000 \n32   \t2.33122  2.29645 \t0.24061  0.28125 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00576 -0.00687\t0.20758  0.21000 \t1.00000 \n64   \t2.28236  2.23198 \t0.24569  0.25092 \t0.66716  0.66716 \t0.67315  0.67315 \t0.10579  0.10579 \t0.02785  0.06250 \t0.17969  0.15094 \t0.33333 \n128  \t2.19468  2.10562 \t0.26196  0.27848 \t0.59637  0.56762 \t0.68157  0.68499 \t0.11952  0.12510 \t0.19194  0.35859 \t0.33357  0.48984 \t0.22232 \n256  \t2.07834  1.96110 \t0.27258  0.28329 \t0.50282  0.43705 \t0.66466  0.65277 \t0.07577  0.04501 \t0.47086  0.75195 \t0.62883  0.92641 \t0.16590 \n512  \t1.96907  1.85938 \t0.27333  0.27408 \t0.39580  0.30466 \t0.65040  0.63826 \t0.03666  0.00335 \t0.66250  0.85488 \t0.81405  1.00000 \t0.12816 \n1024 \t1.89106  1.81289 \t0.27274  0.27215 \t0.30511  0.22116 \t0.62988  0.61089 \t0.01763  0.00002 \t0.77481  0.88734 \t0.90694  1.00000 \t0.10044 \n1499 \t1.85787  1.78624 \t0.27467  0.27882 \t0.26495  0.18157 \t0.62375  0.61102 \t0.01191  0.00004 \t0.81621  0.90556 \t0.93641  1.00000 \t0.08811 \noptimal action prediction accuracy =  0.2727\noptimal neg log loss = 0.2502\noptimal const log loss = 0.6730\nbno  \tloss     since   \tacc      since   \tneg      since   \tconst    since   \treg      since   \tpol      since   \tgreedy   since   \teps     \n0    \t2.39318  2.39318 \t0.18000  0.18000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.03000  0.03000 \t-0.14000 -0.14000\t1.00000 \n1    \t2.38741  2.38163 \t0.17500  0.17000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.09500  0.16000 \t-0.20000 -0.26000\t1.00000 \n2    \t2.38598  2.38312 \t0.18333  0.20000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.07000  0.02000 \t-0.20667 -0.22000\t1.00000 \n4    \t2.38356  2.37993 \t0.18400  0.18500 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.04400  0.00500 \t-0.17600 -0.13000\t1.00000 \n8    \t2.37563  2.36571 \t0.19889  0.21750 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.01889  -0.01250\t-0.17333 -0.17000\t1.00000 \n16   \t2.36122  2.34501 \t0.21824  0.24000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t-0.00059 -0.02250\t-0.17059 -0.16750\t1.00000 \n32   \t2.33165  2.30024 \t0.24394  0.27125 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00000  0.00000 \t0.00121  0.00312 \t-0.18182 -0.19375\t1.00000 \n64   \t2.28116  2.22908 \t0.25186  0.26004 \t0.69037  0.69037 \t0.69756  0.69756 \t0.19774  0.19774 \t-0.02969 -0.06156\t-0.18708 -0.19250\t0.35163 \n128  \t2.19501  2.10753 \t0.26406  0.27645 \t0.63165  0.61147 \t0.69093  0.68865 \t0.14776  0.13058 \t0.03806  0.10688 \t-0.02225 0.14516 \t0.22568 \n256  \t2.09439  1.99298 \t0.26758  0.27111 \t0.53255  0.46596 \t0.66404  0.64597 \t0.10612  0.07815 \t0.28237  0.52859 \t0.31016  0.64516 \t0.16692 \n512  \t1.98281  1.87080 \t0.26355  0.25951 \t0.42233  0.33019 \t0.64464  0.62843 \t0.05210  0.00694 \t0.56903  0.85680 \t0.65441  1.00000 \t0.12853 \n1024 \t1.89405  1.80512 \t0.26797  0.27241 \t0.32590  0.23738 \t0.62773  0.61221 \t0.02494  0.00001 \t0.72821  0.88771 \t0.82703  1.00000 \t0.10057 \n1499 \t1.86571  1.80455 \t0.26852  0.26969 \t0.28073  0.18736 \t0.61307  0.58276 \t0.01681  0.00001 \t0.78478  0.90684 \t0.88181  1.00000 \t0.08819 \n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x180 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1670344707980
        }
      },
      "id": "5fa407d9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}